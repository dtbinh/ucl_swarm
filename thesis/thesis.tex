\documentclass{report}
\usepackage{setspace}
%\usepackage{subfigure}

\pagestyle{plain}
\usepackage{amssymb,graphicx,color}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{a4wide}
\usepackage{amsmath}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{textcomp}
\usepackage{setspace}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage[newfloat]{minted}
\usepackage{caption}
\usepackage{pdflscape}
\usepackage{geometry}
\usepackage{ntheorem}
\usepackage[titletoc]{appendix}

\usepackage[T1]{fontenc}
\usepackage{mathpazo}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
\else\Gin@nat@width\fi}
\makeatother

\usepackage{adjustbox} % Used to constrain images to a maximum size 
\usepackage{xcolor} % Allow colors to be defined
\usepackage{enumerate} % Needed for markdown enumerations to work
\usepackage{geometry} % Used to adjust the document margins
\usepackage{amsmath} % Equations
\usepackage{amssymb} % Equations
\usepackage{textcomp} % defines textquotesingle
% Hack from http://tex.stackexchange.com/a/47451/13684:
\AtBeginDocument{%
	\def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
}
\usepackage{upquote} % Upright quotes for verbatim code
\usepackage{eurosym} % defines \euro
\usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
\usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
\usepackage{fancyvrb} % verbatim replacement that allows latex
\usepackage{grffile} % extends the file name processing of package graphics 
% to support a larger range 
% The hyperref package gives us a pdf with properly built
% internal navigation ('pdf bookmarks' for the table of contents,
% internal cross-reference links, web links for URLs, etc.)
\usepackage{hyperref}
\usepackage{longtable} % longtable support required by pandoc >1.10
\usepackage{booktabs}  % table support for pandoc > 1.12.2
\usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
\usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
% normalem makes italics be italics, not underlines




% Colors for the hyperref package
\definecolor{urlcolor}{rgb}{0,.145,.698}
\definecolor{linkcolor}{rgb}{.71,0.21,0.01}
\definecolor{citecolor}{rgb}{.12,.54,.11}

% ANSI colors
\definecolor{ansi-black}{HTML}{3E424D}
\definecolor{ansi-black-intense}{HTML}{282C36}
\definecolor{ansi-red}{HTML}{E75C58}
\definecolor{ansi-red-intense}{HTML}{B22B31}
\definecolor{ansi-green}{HTML}{00A250}
\definecolor{ansi-green-intense}{HTML}{007427}
\definecolor{ansi-yellow}{HTML}{DDB62B}
\definecolor{ansi-yellow-intense}{HTML}{B27D12}
\definecolor{ansi-blue}{HTML}{208FFB}
\definecolor{ansi-blue-intense}{HTML}{0065CA}
\definecolor{ansi-magenta}{HTML}{D160C4}
\definecolor{ansi-magenta-intense}{HTML}{A03196}
\definecolor{ansi-cyan}{HTML}{60C6C8}
\definecolor{ansi-cyan-intense}{HTML}{258F8F}
\definecolor{ansi-white}{HTML}{C5C1B4}
\definecolor{ansi-white-intense}{HTML}{A1A6B2}

% commands and environments needed by pandoc snippets
% extracted from the output of `pandoc -s`
\providecommand{\tightlist}{%
	\setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}

% Additional commands for more recent versions of Pandoc
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}


% Define a nice break command that doesn't care if a line doesn't already
% exist.
\def\br{\hspace*{\fill} \\* }
% Math Jax compatability definitions
\def\gt{>}
\def\lt{<}

\newtheorem{theorem}{THEOREM}
\newtheorem{lemma}[theorem]{LEMMA}
\newtheorem{corollary}[theorem]{COROLLARY}
\newtheorem{proposition}[theorem]{PROPOSITION}
\newtheorem{remark}[theorem]{REMARK}
\newtheorem{definition}[theorem]{DEFINITION}
\newtheorem{fact}[theorem]{FACT}
\theoremseparator{:}
\newtheorem*{hyp}{Hypothesis}

\newtheorem{problem}[theorem]{PROBLEM}
\newtheorem{exercise}[theorem]{EXERCISE}
\def \set#1{\{#1\} }

\newenvironment{proof}{
PROOF:
\begin{quotation}}{
$\Box$ \end{quotation}}

\newenvironment{code}{\captionsetup{type=listing}}{}
\SetupFloatingEnvironment{listing}{name=Source Code}


\newcommand{\nats}{\mbox{\( \mathbb N \)}}
\newcommand{\rat}{\mbox{\(\mathbb Q\)}}
\newcommand{\rats}{\mbox{\(\mathbb Q\)}}
\newcommand{\reals}{\mbox{\(\mathbb R\)}}
\newcommand{\ints}{\mbox{\(\mathbb Z\)}}
\newcommand{\rom}[1]{\uppercase\expandafter{\romannumeral #1\relax}}

% Pygments definitions

\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
\let\PY@ul=\relax \let\PY@tc=\relax%
\let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
\PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
\PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


% Exact colors from NB
\definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
\definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}




% Prevent overflowing lines due to hard-to-break entities
\sloppy 
% Setup hyperref package
\hypersetup{
	breaklinks=true,  % so long urls are correctly broken across lines
	colorlinks=true,
	urlcolor=urlcolor,
	linkcolor=linkcolor,
	citecolor=citecolor,
}

%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{  	{ \includegraphics[scale=.5]{ucl_logo.png} }\\
{{\Huge A Comparative Analysis of Multi-Robot System Strategies for the Automation of Green Wall Maintenance} }\\
	  }
\date{Submission date: 03 September 2018}
\author{Sylvester Wachira Ndaiga\thanks{
{\bf Disclaimer:}
This report is submitted as part requirement for the MSc in Robotics and Computation at UCL. It is
substantially the result of my own work except where explicitly indicated in the text.
\emph{Either:} The report may be freely copied and distributed provided the source is explicitly acknowledged
\newline  %% \\ screws it up
\emph{Or:}\newline
The report will be distributed to the internal and external examiners, but thereafter may not be copied or distributed except with permission from the author.}
\\ \\
MSc Robotics and Computation\\ \\
Professor Stephen Hailes}



\begin{document}
 
\onehalfspacing
\maketitle
\begin{abstract}

This paper presents an analysis of two operational strategies of a UAV-based, Multi Robot System tasked with performing the robotic maintenance of a Green Wall System in simulation. Hypothesis testing is employed to present a statistical comparison of swarm-inspired vs generic lawn mower motion approaches to coverage path planning and cooperative control in the robot collective. Each agent localizes, classifies and acts upon randomly distributed coplanar targets, functionally symbolic of a plant-abundant, vertical wall planter. Global objectives are probabilistically respected by locally acting agents via limited sensing and communication techniques. Additionally, a data pipeline and in-simulation, sample dataset are provided for research posterity. Finally, an outline of open research questions and directions is laid out for future investigation.

\end{abstract}
\tableofcontents
\setcounter{page}{1}

\newpage
\section*{Acknowledgments}
God,Nunu,Steven Hailes,Carlo Pincorillo, Andrew Symmington,Family,Friends.Cardi B.
\vspace{5cm}
\\
If you look for truth, you \textit{may} find comfort.
If you look for comfort, you \textit{will} find despair.
\\
~ CS Lewis

\chapter{Introduction}

The emergence and proliferation of drones in the commercial, consumer and military sectors is widely evidenced and supported in literature and industry. This is largely on account of continual advances in hardware miniaturization, cost and robustness coupled with technological leaps in navigational intelligence and communication modalities. While encouraging, notable limitations are continually surfaced in furthering their applicability to unstructured environments. The latter manifests as task and obstacle ambiguity and makes robotic operation challenging at best and intractable at worst, with an extensive body of attendant work available in the robotics literature. A novel approach to solving this environment dynamicity problem is presented in the form of Robot Swarms Systems; collectives of locally-acting robots that work towards the attainment of set objectives. This capability of Robot Swarms Systems to outperform Monolithic Systems is referred to as \textit{force multiplication} \cite{Yang2018} and is a central driver of the field. It is a promising discipline and a notable entry in Yang et als' \textit{Grand challenges of Science Robotics} \cite{Yang2018}. Alternative nomenclature for the term Robot Swarms exists in the robotics literature \cite{Beni2005a} \cite{Sahin2005} \cite{Iocchi2001}; for exactness we elect to make use of the term Multi Robot Systems in this work as forwarded by \cite{Iocchi2001}.

Core to this paper's focus is the application of an Unmanned Aerial Vehicle-based, Multi Robot System (MRS) to the automated maintenance of Green Wall Systems (GWSs) as coined in \cite{Perini2011}. The efficiency and capital constraints identified in current GWSs include, but are not limited to, \cite{Holt2018}:
\begin{itemize}
	\item High initial capital.
	\item Exorbitant energy costs.
	\item Extensive environmental control system requirements.
	\item High Carbon Footprint.
\end{itemize}

We postulate that the automation of such systems by a MRS will not only mitigate the aforementioned costs, but result in much more robust and flexible systems that are amenable to integration in human society as envisioned by Mark Weiser in his aphorism: "\textit{The most profound technologies are those that disappear. They weave themselves into the fabric of everyday life until they are indistinguishable from it}" \cite{Weiser2002}. More directly, the selection of GWSs as an application area is informed by the growing academic \cite{Manso2015} \cite{Graamans2018} \cite{Neil2017} and industry \cite{Gmi2017} \cite{Holt2018} interest in the economic viability of sustainable urban ecologies; key among these being Vertical Farming Systems. The latter is considered increasingly exigent given the concerning rise in food insecurity \cite{Yang2018} in the wake of global population growth trends juxtaposed against finite agricultural and arable land availability \cite{Banerjee2014}. Henceforth, this paper refers to the proposed system under consideration as a Green Wall Multi Robot System (GREW-MRS).

In this work, a GREW-MRS is designed and developed in two conditioned studies to assess the performance benefits conferred in utilising both swarm-inspired optimization and behaviours. The pragmatic benefits of employing such systems in place of individual agent / monolithic systems include \cite{Yang2018}:
\begin{itemize}
	\item \textit{System modularity} - the collective robustness to disturbances and resilience to adversarial disruptions.
	\item \textit{System flexibility} - the collective responsiveness to human control and ability to adapt to changing conditions.
	\item \textit{System economy} - the collective cost effectiveness granted by the simplistic robot designs espoused as a fundamental trait of swarm robots.
\end{itemize}

\section{Objectives}\label{objectives}

The main goal of this paper is to statistically highlight the performance effect of Swarm Optimization (SO) and Swarm Behaviours on Multi Robot Systems when applied to the automation of Green Wall System maintenance. This will be compared to a naive Lawn Mower Motion \cite{Cao1988} approach that utilises a sweeping movements to perform region filling; inadvertently maximising target space coverage probability at the expense of time to task completion. The evaluation shall be approached as a hypothesis test, with the null $H_o$ hypothesis, (\ref{hyp:null}) and alternate hypothesis, $H_a$ (\ref{hyp:alt}) stated thusly:

\begin{hyp}[$H_o$] \label{hyp:null}
	The mean \textit{time-to-target-threshold} in the Lawn strategy is \textit{equal} to that of the Swarm-inspired strategy.
\end{hyp}
\begin{hyp}[$H_a$] \label{hyp:alt}
	The mean \textit{time-to-target-threshold} in the Lawn strategy is \textbf{less than} that of the Swarm-inspired strategy.
\end{hyp}

To aid understanding, a brief ontology of the field of Swarming Systems must first be laid out. This is on account of the esoteric and somewhat exotic nature of the topic at hand, albeit reasonably catered to by key literature \cite{Beni2005a} \cite{Iocchi2001} \cite{Galceran2013}. Additionally, an investigation into appropriate simulation platforms and hypothesis testing techniques is elucidated that ensures experimental replicability and validity. The latter are necessary, keystone conditions for reproducible experimental research to which this work aspires to produce.

\section{Challenges}
A number of notable challenges exist, chief among them a dearth of established research frameworks and methodologies towards the performance analysis of goal-oriented Multi Robot Systems inspired by Swarming Systems. This is particularly true for convergence and efficiency evaluation of metaheuristic optimization algorithms present in the Swarm Optimization literature \cite{Yang2011}. A causal corollary of this is the arguably highly-extensible nature of such systems which allow for an exceedingly diverse swarm configuration space. This makes the task of performing benchmark analysis a tricky affair given all the variants of each implementation that are possible. However, a number of similarly oriented, statistical evaluation approaches to popular Swarm Optimization (SO) algorithms exist in literature \cite{Selvi2010} \cite{Yang2011} with sample benchmark datasets available \cite{Gerhard1991}.

A balance between computational cost and real-world fidelity must be met when attempting to perform robotic simulations. To utilize accurate dynamic models and near hyper-realistic visualization, the chosen simulator must be run on or make use of high performance computing resources and features. This exceedingly costly computational prerequisite has been an archilles' heel in Robotics Development Environment (RDE) research and a focal point in the Computer Graphics (CG) domain. Recent advances in the latter are however turning the tide with real-time ray tracing poised to go mainstream this year \cite{RTracing}, opening the door to a new swath of simulator realism that has so far been the preserve of industry heavyweights. Additionally, recent contributions to the RDE field \cite{Shah2018} point to both a renewed interest and recognised demand for advanced robotics simulators. This demand is made apparent in this work where the ease of experiment simulation and data generation was constrained by the computational capability of the non-specialised computing hardware utilised. The latter had the following specifications:
\begin{itemize}
	\item Intel\textsuperscript{R} Core\textsuperscript{TM} Quad-Core i7-4700MQ CPU rated at 2.40GHz
	\item 12GB of DDR3 Synchronous RAM rated at 1600MHz.
	\item 1 Terabyte Harddrive rated at 5400 rpm.
	\item NVIDIA\textsuperscript{R} GeForce\textsuperscript{R} GT 755M with 2GB Graphics Memory.
\end{itemize}

While the above system is moderately capable, it nonetheless took 42 minutes (computed from outputted logfile metadata) to generate the sample, analysis-adequate dataset provided with this project. Another notable computational trap was noticed by the author in the storage of the simulation data. It was noticed that while utilising a single CSV formatted file to store the simulation data is simpler in theory to handle, it would likely be impractical for extensively large experiments, leading to the generation of memory-costly datasets. These would prove difficult to load into random access memory (RAM) by statistical analysis libraries like Pandas \cite{Pandas}. The sample dataset provided sits at approximately 400kB (uncompressed) after an iteratively developed data collection design process. Prior to this, a similarly sampled dataset was sized at approximately 1GB, requiring a chunked data loading technique. In short, adequate time and consideration must be placed on how one chooses to generate and work with the simulation data.

\section{Contributions}
This work makes the following contributions to the field:

\begin{itemize}
	\item A novel approach to comparatively evaluate the performance of GREW-MRS strategies and implementations. The application of statistical testing is also introduced with novel measurement variables proposed for wider consideration. Data generation is addressed with appropriately developed tooling provided.
	\item A novel and simple simulation pipeline with code made freely available. This work's software repository is made freely available and is scripted as an ARGoS experiment that is dynamically configured with the help of a shell script. It can be found at \url{https://github.com/wndaiga/swarm_ucl} \cite{SWARMCODE}.
	\item A sample dataset of 10 independently and randomly seeded simulation trials over a range of Green Wall target/plant numbers (2-50).
\end{itemize}

\section{Outline}

In chapter \ref{background}, we provide the historical context and progress of the fields of Swarm Optimization and Robotics research, detailing their genesis in cellular automata and the efforts taken to better define and demarcate the field into distinct interest areas. A cursory overview of Coverage Path Planning (CPP) and Green Wall Systems (GWSs) is also provided as a contextual backdrop to this work. The precise aim of this chapter is to surface and instill key dogmatic themes of the fields and thereafter walk the reader through prior related work.  In chapter \ref{implementation}, we present the experimental design with its novel measurement variables and the system design implemented in this project, thereafter providing an overview of the selection criteria deemed necessary to perform the statistical experimental analysis central to this project. The endogeneous and exogeneous sources of innaccuracies are delineated with the cooperative control and path planning strategies laid out in full. In chapter \ref{evaluation}, we evaluate our approach using the Student's t-test \cite{Kennedy1995} and identify gaps and oversimplifications where applicable. In chapter \ref{conclusion}, a number of possible research directions and areas are suggested for future investigation.

\chapter{Background} \label{background}

The GREW-MRS application objective requires the interaction of a myriad of research domains, including but not limited to, UAV Stabilization, Optimal Control, Navigation, Obstacle Avoidance, Wireless Communications and Computer Vision \cite{Guerrero2013}. This wide problem scope is hardly solvable in monolithic systems due to the energy and computational constraints present in currently available platforms. Multi Robot Systems are uniquely positioned to robustly and flexibly solve for these constraints through cooperative control.

In this work, agent navigation is formulated as a Travelling Salesman Problem which is easily solvable through a myriad of Swarm Optimization (SO) algorithms that exist in literature. For tractability, we will not consider obstacle nor collision avoidance schemes; however, these are well-researched in the literature \cite{Galceran2013}. This project will, however, focus on two SO implementations; the Discrete Particle Swarm Optimization (DPSO) and Ant Colony Optimization (ACO) algorithms. Their selection was on account of their popularity in the literature \cite{Tan2013} and simplicity in design. SOs have been shown to be well adapted to solving these types of problems and exhibit beneficial qualities to systems that implement them.

Foundational to the development and advancement of the Swarm Robotics (SR) field is the ability to generate and evaluate high-fidelity, dynamical models in simulation \cite{Taylor2014}. The importance of such tooling cannot be overstated given the overheads and constraints involved in the testing of costly mobility and transportation platforms whilst enhancing the ease of validating several system aspects. The widespread usage of simulations in the field can largely be attributed to the fact that they are easier to setup, are less expensive, are normally faster and are more convenient to use than physical swarm hardware \cite{WeBot2004}. Fortunately, this has been bolstered by the availability of advanced and highly extensible multi-robot simulators such as Gazebo, USARSim, ARGoS \cite{Pinciroli2014}, WeBot and MORSE \cite{Morse2011}. Complementary to this is the growth and advancement of three key drivers of robot swarms: the hyper-convergence of hardware and software technologies, novel wireless networking features and strategies and a notable reliance of cognitive systems on Machine Learning and Artifical Intelligence \cite{Yang2018}. Of note when considering wireless networking technologies is the incorporation of robust mesh networking specifications \cite{Blue2018} that confer practical solutions to encumbured local communication in robot swarms. However, more central to this need for standardised tooling is the fact of the disciplines' pre-paradigmatic stage, defined by Kuhn et al \cite{Kuhn2015} as a nascent period marked by a lack of scientific consensus on appropriate terminologies, methods and experiments. These are necessary for the construction of a scientific framework within which verifiable and replicable research can be performed. This is especially pertinent if prevailing literature on the projected impact of the field is to be realized \cite{Yang2018}. With the pioneering work of Beni et al \cite{Beni2005a}, apt consideration is accorded to the terminology of the discipline of Swarm Systems. Therein, the taxonomies of the distinctive qualities of Swarm Optimization (SO) and Swarm Robotics (SR) systems are laid out with further elucidation provided as to the nature of their genesis and applicability. While the foundation laid out by \cite{Beni2005a} is found to be necessary, it is not entirely sufficient to develop a conceptually-complete framework for scientific investigation. This is cautiously addressed by the works of \cite{Iocchi2001} and \cite{Sahin2005} that, in addendum, reinforce the fact of the disciplines' early stage and lack of common scientific framework. This can be seen to be reflected in the numerous alternate and sometimes conflicting classifications found in existing literature \cite{Tan2013}. Wherever possible, and for purposes of clarity and consistency, this project will highlight the choices made in the definition of key terms and ideas.

We maintain that a small-scale system employing probabilistically-modelled agent behaviours is capable of achieving performant system operation. In this work, agent navigation is addressed as a path planning problem solvable with the help of Swarm Optimization (SO). The latter is a growing sub-field of Swarm Intelligence (SI), a field whose industry reports opine widespread commercialization by 2020, driven by the increase in its usage for solving big data problems, the rising adoption of swarm-based drones in military and the need for SI in transportation and logistics \cite{Swarm2030}. This provides the SI research community with key market gaps and consequent opportunities towards the development of novel SI applications for varied industries. This project hopes to serve as one such reference study.

\section{A Brief Overview}
In \cite{Beni2005a}, a crucial distinction between Swarm Optimization (SO) and Swarm Robotics (SR) is conveyed where the former is subsummed under Swarm Intelligence (a subfield of Artificial Intelligence) as meta-heuristic applicable to the optimization of objective functions (pattern analysis) and the latter is largely concerned with the coordinated operation of physical agents (pattern synthesis). In the main, they both detail avenues through which intelligent behaviour is achieved by a decentralised, non-synchronous group of quasi-homogeneous, simple units, not in "\textit{Avogadro-large}" numbers that would be extraordinarily large. Here, intelligent behaviour is defined as the production of improbable and unpredictable ordered outcomes.

In dealing with physical agents, a noteworthy benefit conferred by these modularized, mass-produced, interchangeable and possibly disposable robotics systems are reliability guarantees by way of the highly redundant nature of said systems' members. This confers these systems certain performance and robustness gains over monolithic systems \cite{Iocchi2001}. Complementary to this, intelligent behaviour through pattern analysis allows for practical solutions to NP-hard and NP-complete problems such as combinatorial optimization in path planning \cite{Yan2012}. They have additionally been applied to a vast cornucopia of areas in design, scheduling and planning, data mining, machine intelligence and many others with an extensive body of work available in the literature \cite{Yang2011}.

\subsection{Swarm Optimization}
The field of Swarm Optimization (SO) is only just approaching the three decade mark with Gerardo Beni and Jing Wang credited with first coining the term \textit{Swarm Intelligence} (SI) in 1989 \cite{Garg2009}. Despite its rather young history, its use in solving optimization problems is well covered and encouraged in literature, largely attributable to its enhanced performance when compared to other optimization methods such as neural networks, machine learning and genetic computation. This has been investigated in the optimization literature, with SO algorithms characterized as exhibiting generally better performance in computing speed, accuracy and memory size \cite{Tran2016}.

Core to this performance is the tuned attainment of optimal parameters that informs their exploitation and exploration characteristics in solution state space. This tuning reliance presents the two main caveats of SO algorithms; they are prone to premature convergence and are not robust against local minima \cite{Cuevas2013}. However, this is readily corrected for by grafting SO implementations with Generative Iterative Algorithms (GIA) such as Evolutionary Algorithms, Simulated Annealing (SA) and Tabu Search (TS). GIAs are especially suitable for this use case due to their ability to solve ill-posed problems where some parameters are prior unknowns \cite{Youssef2001} through random population mutations. This ability to hybridise SO algorithms is a growing research area with numerous algorithm variants continually proposed \cite{Tran2016} \cite{Coello2006} \cite{Phung2017}. These extensions, when properly designed and implemented, increase the convergence speed of the considered systems \cite{Tran2016}. In the main, the following benefits are conferred to systems that implement SO algorithms for pattern analysis \cite{Cuevas2013}:
\begin{itemize}
	\item \textit{Scalability}.
	\item \textit{Fault tolerance}.
	\item \textit{Adaptation}.
	\item \textit{Speed}.
	\item \textit{Modularity}.
	\item \textit{Autonomy}.
	\item \textit{Parallelism}.
\end{itemize}

\subsection{Swarm Robotics}
Beni et al \cite{Beni2005a} made a case for the redefinition of Swarm Intelligence (SI) as applied to robotics systems, noting that the realization of swarm intelligent robots is a distant goal. In doing so, they formalized "\textit{swarm robotics}", "\textit{collective robotics}" and "\textit{distributed autonomous robotic systems}" as more appropriate terms; the selection of which should be independent of group size attributable to their scalability property. This counterintuitively means that application-specific considerations given to the diversity and scale of the developed systems actually makes them less "\textit{swarmy}".

A number of core swarm characteristics are known and established in the swarm robotics literature \cite{Brambilla2013a}:
\begin{itemize}
	\item Robots are autonomous.
	\item Robots are situated in the environment.
	\item Robots sensing and communication is limited and local.
	\item Robots do not have access to centralised control and/or global knowledge.
	\item Robots cooperate to complete tasks.
\end{itemize}

It should, however, be taken into account that there presently exist different characterizations of Swarm Robotics (SR) in the literature \cite{Sahin2005} \cite{Beni2005a} \cite{Dorigo2013} \cite{DorigoSahin2004}. The most applicable swarm description of the GREW-MRS was found in the works of Ioochi et al \cite{Iocchi2001}. They provided a suitable definition and framework for the characterization of swarm robotics as a \textit{Multi Robot System} (MRS) forwarded as a particular instance of a \textit{Multi Agent System} (MAS). It is concerned with the reactivity and social deliberation of the collective which consist of resource-constrained agents that exhibit limited sensing and communication capabilities. Ioochi's taxonomy is depicted in figure \ref{fig:MRS_taxonomy} and details the varying feature-sets and capabilities presently available to MRS applications.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{images/MRS_taxonomy.png}
	\caption{A Multi Robot System Taxonomy \cite{Iocchi2001}}
	\label{fig:MRS_taxonomy}
\end{figure}

In the GREW-MRS proposed in this system, we proposition a Cooperative, Unaware and Strongly Coordinated \& Centralized system.

\newpage

\subsection{Coverage Path Planning}
Point-to-point path planning for mobile robots is a well-studied area of robotics research with a myriad of techniques developed and proposed towards achieving robust, collision-free, goal-oriented navigation in the presence of obstacles and uncertainties. While this is an established and commonplace feature of Monolithic Robots in literature and industry, the same cannot be easily said for Multi Robot Systems (MRS). This is especially so when considering objective-oriented Coverage Path Planning (CPP), a topic of major interest in robotics literature \cite{Macas2009}. In the case of MRS, this is due to the complexity of the problem that depends on a number of factors \cite{Yan2014}, some of which are:
\begin{itemize}
 \item \textit{Robot characteristics}: With MRS, the diversity of the collective is a large determining factor where heterogeneous populations may lead to widely diverging results. As such, homogeneous robot teams are generally preferred as they confer some system reliability.
 \item \textit{Terrain properties}: A larger workspace would require a larger team size to both efficiently and sufficiently perform required tasks. Additionally, obstacle density and shape can impede the rate at which robot collectives perform work in the target space.
 \item \textit{Environment Dynamicity}: Changing environments pose a challenge to the maintenance of system guarantees where path planning and obstacle avoidance strategies would increasingly interfere with coordination control.
\end{itemize}

Given the above limitations, a number of objectives must still be met by the robot collectives. In the case of the GREW-MRS system presented herein, Cao et al \cite{Cao1988} defined a number of critera that a robot system must meet for optimal coverage:
\begin{itemize}
	\item A robot must move through all the points in the target area covering it completely.
	\item A robot must fill the region without overlapping paths.
	\item Continuous and sequential operation without any repetition of paths is required.
	\item A robot must avoid all obstacles.
	\item Simple motion trajectories (e.g., straight lines or circles) should be used (for simplicity in control).
	\item An “optimal” path is desired.
\end{itemize}

However, Galceran et al \cite{Galceran2013} critique that it may not always be possible to achieve all six requirements in dynamic environments and posit that a prioritization of criteria is necessary.

Choset et al \cite{Choset2001} classified Coverage Path Planning (CPP) algorithms as heuristic or complete depending on their global coverage guarantees. In this work, a semi-heuristic approach is considered given the probabilistic nature accorded to the coordination control implemented at the swarm level. independently of this initial classification, CPP algorithms can also be classified as online or offline; in the latter the environment is assumed to be known whereas online approaches do not have access to the same and must rely on real-time sensing and area-sweeping techniques. Offline systems, while simpler to conceptualize and implement in simulation, do not reflect real-world conditions where the environment is known to be dynamic and under the influence of exogenous factors. Online strategies offer more robust solutions to this issue despite being much harder to grapple with from a technical standpoint towards the achievement of globally consistent maps. Online strategies are better understood as methods towards learning environment maps with numerous innovative approaches available in the enhanced and hybridised forms of Filters, Smoothers and Graphs generally subsumed under Simultaneous Localization and Mapping (SLAM) systems. SLAM systems have been a have been a major area of research for over two decades (Merging Partially Consistent Maps) with numerous implementation proposals available \cite{Lu1997} \cite{Grisetti2007} \cite{Montemerlo2002} \cite{Olson2006} \cite{Smith1987} \cite{Thrun2004}. However, the consideration and implementation of online systems was decidedly a secondary focus area of this work and, subsequently, a simpler, offline method was utilised. This is also consistent with the literature, it is found only possible to find an optimal solution to the Coverage Path Planning problem for an \textit{a priori} known, or partially known environment \cite{Galceran2013} which by definition entail the utilisation of offline systems.

\subsection{Green Wall Systems}
Green Wall Systems, also referred to as Living Walls \cite{Sheweka2011} or Vertical Greening Systems \cite{Manso2015} in the literature are approaches to the enhancement and restoration of built-up urban environments with a number of notable benefits being:
\begin{itemize}
	\item Reduction of greenhouse gas concentrations in urban areas.
	\item Mitigation of Urban Heat Island (UHI) effect due to the evaporative cooling effect of vegetation.
	\item Reduced costs associated with Building Environmental Controls (e.g. HVAC systems).
\end{itemize}

The crucial urgency of addressing the above is made imperative by recent legislative efforts towards combating climate change, with one pivotal example being the \textit{Paris Agreement} of 2015 \cite{UNFCCC2015}. However, an identified and somewhat ironic issue with currently available green walls is their seemingly stunted evolution as scalable, sustainability interventions on account of a lack of published comparative studies and research \cite{Manso2015} \cite{Kalantari2017}.

\begin{figure}[h]
	\begin{subfigure}[b]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/IndirectGreenFacade.png}
		\caption{An Indirect Green Facade \cite{Manso2015}}
		\label{fig:vertical_farm}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.505\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/LivingWallSystem}
		\caption{A Living Wall System \cite{Manso2015}}
		\label{fig:vertical_garden}
	\end{subfigure}
	\caption{There exists classifications of vertical wall gardens available in literature \cite{Manso2015}.}
	\label{fig:vertical_applications}
\end{figure}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{images/MexicoColumns.jpg}
	\caption{Project \textit{Via Verde}: Green Wall Systems deployed in Mexico to combat urban pollution \cite{Rathi2017}}
	\label{fig:mexico_columns}
\end{figure}

Of particular interest to the author is the similarity in the applied scenarios of the presented green wall system and vertical farming. The two applications can be considered equal in most technical respects, with the main difference largely being the consideration of human consumption qualities in the case of vertical farms. Vertical Farming can be defined as an effort towards the development of sustainable, urban-located agriculture and has attracted considerable industry interest in recent years \cite{Banerjee2014}. Recent market projections indicate a market size estimated to amount to over 2.25 Billion USD by 2024 in the United States alone \cite{Gmi2017}.

The viability of automating green wall system maintenance as well as vertical farming tasks lies in the typically high cost overruns associated with the construction and maintenance of these largely closed ecological systems. This is traditionally done with the help of human labour, with the extenuating risk that these tasks may expose them to (e.g. the scaling of exceedingly tall installations). Additionally, the manual and semi-manual piloting of UAVs can be long and tedious for operators especially when the presence of wind gusts and turbulence is endemic in urban areas; a consequence of the Urban Canyon Effect. The use of a GREW-MRS to achieve automation of the same would drastically reduce this encumberance and constitutes a novel approach towards advancing the economic practicality \cite{Bircher2015} of aerial robots in daily human life beyond the current focus on consumer curiosities and entertainment light shows \cite{IQ2016}.

\section{Related Work}

While the determination of standardised metrics to evaluate Swarm and Multi Robot System performance vary from application to application, a number of definitions stand out in the robotics literature that deserve mention. In the case of Coverage Path Planning, terms such as path length and time to completion, are present in the literature \cite{Galceran2013} when considering the optimality of generated solutions.

Cuevas et al \cite{Cuevas2013} developed Social Spider Optimization (SSO) that they comparatively evaluated against the Particle Swarm Optimization (PSO) and Artificial Bee Colony (ABC) algorithms. They similarly utilised a hypothesis testing framework to compare the mean values of each sampled algorithm. In it, they forwarded the Average-Best-So-Far (AB), Median-Best-So-Far (MB) and Standard-Deviation-Best-So-Far (SD) solutions as dependent measurements, testing for a 5\% significance level and finding strong evidence against the null hypothesis that assumed no significant difference between the measured sample variables.

Although it is difficult to surface similarly applied research in the literature, there is work that exhibits parallels to this project. Brien et al \cite{Brien2014} helped define the field of formal verification systems as applied to autonomous robots. They developed a verification software module to assess the probability that performance criteria of autonomous robots can be met despite the uncertainty of real-world conditions. However this was limited to monolithic systems with added work necessary to extend their module to MRS implementations. Selvi et al \cite{Selvi2010} performed a comparative analysis of the Particle Swarm Optimization and Ant Colony Optimization algorithms but did not employ statistical evaluation. Phung et al \cite{Phung2017} developed an enhanced Travelling Salesman Problem (TSP) tractably solved by a discretized PSO algorithm as applied to UAV-based, Structural Health Monitoring (SHM). They formalised Coverage Path Planning (CPP) as a multi-level, Inspection Path Planning (IPP) problem. Their approach alluded to a bipartitioning of the same into an initial Art Gallery Problem, thereafter optimizing the given solution as a Travelling Salesman Problem. Overlapping photos of the target surfaces are taken once the IPP objective is met for later processing. Guerrero et al \cite{Guerrero2013} similarly presented work on the use of Quadcopters towards the structural inspection of bridges, notably implementing the Path Planning as a Travelling Salesman Problem (TSP). DiFranco et al \cite{DiFranco2015} proposed an energy-aware Coverage Path Planning (CPP) algorithm that minimizes the energy consumption of multi-rotor UAVs while achieving multi-objective surveying of a target space.

Fredslund et al \cite{Fredslund2002} investigated the use of multiple leaders in maintaining formations in Swarm Systems through local sensing and minimal communication i.e. without the sharing of global information with local agents. Matari et al \cite{Matari1995} utilised simple behaviours towards the development of a global flocking behaviour in a group of 13 mobile robots. These behaviours included Safe-Wandering, Following, Dispersion, Aggregation and Homing. Bircher et al \cite{Bircher2015} designed and developed a fast algorithm for the efficient inspection path planning of varied structures based and implemented on monolithic UAV systems. They advanced a fast implementation of the Lin-Kernighan-Helsgaun Heuristic (LKH) TSP solver. Optimization of such algorithms is a key area of work in this field due to the limited computing and energy resources available on current aerial quadcopter systems and is a valuable research direction for the field.

A major distinction difference between this project and that of \cite{Matari1995} and \cite{Fredslund2002} is the domain space of the mobile robots. The latter works were implemented on terrestrial-based mobile robots whereas this project considers an application to UAV-based robots. As a matter of observation, the author found there to exist a much larger body of work related to the Swarm and Multi Robot System analysis of terrestrial-based robots. This can be said to be attributable to their rather simpler 2D domain space as compared to UAV-based systems' 3D domain.

\chapter{Implementation} \label{implementation}

In this work, the development of a GREW-MRS towards automated Green Wall System maintenance is presented in simulation. There exists a wide and diverse problem-set associated with the stated objective that is covered in the corpus of robotics literature. We argue for the usefulness of Swarm Optimization (SO) techniques to solving Coverage Path Planning (CPP) formulated as a Travelling Salesman Problem (TSP). More specifically, we implement the Particle Swarm Optimization (PSO) \cite{Kennedy1995} and Ant Colony Optimization (ACO) \cite{Dorigo1997} metaheuristic optimization algorithms. Coordination Control of each MRS agent is probabilistically controlled through virtual stigmergy and a strongly centralised hierarchy. Additionally, Cao et al's \cite{Cao1988} CPP optimality criteria was adapted through a consideration of a number of limitations, as suggested by \cite{Galceran2013}:
\begin{itemize}
	\item The utilised SO algorithm implementations are 2D-based and therefore we cannot guarantee that there will be no overlapping paths.
	\item A lack of motion planning features in the ARGoS simulator meant that obstacle avoidance while necessary, would need to be implemented either from the ground up or through planners such as OMPL \cite{OMPL}. Additionally, the lawnmower problem is notable in that it is not designed to account for obstacles \cite{Galceran2013}.
	\item The use of probabilistic behaviours for cooperation control means that complete target area coverage cannot be guaranteed.
\end{itemize}

In this work, a semi-heuristic, offline approach to solving the CPP problem is implemented. In the CPP literature, this is typically solved by cellular decomposition techniques where the target space is broken into sub-regions \cite{Choset2001}. The GREW-MRS developed herein, however, has access to a global map that contains the coordinates of all target locations. The latter are then passed to the TSP solver as city nodes and an optimal path generated thereafter. This solver makes use of the Discretized Particle Swarm Optimization (DPSO) or Ant Colony Optimization (ACO) algorithms with two key benefits being their relative speed and robustness to combination explosion, an encumbrance to traditional algorithms such as the Cupity Algorithm and the Dynamic Programming Algorithm. However, these benefits come at the cost of optimal global solution guarantees as previously mentioned \cite{Yan2012}.

In this paper's case, the DPSO and ACO were selected on account of their prolific prominence in the field \cite{Selvi2010}. The implementations utilised herein were based on C++ codebases of the same openly available online \cite{PSOTSP} \cite{ACOTSP}, both found to have followed the relevant literature on PSO \cite{Kennedy1995} and ACO \cite{Dorigo1999} algorithms.

\section{Experimental Design}
A number of guiding principles exist in the experimental design literature and are known to be necessary to planning research experiments \cite{Field2012}:
\begin{itemize}
	\item Empirical.
	\item Measurement.
	\item Replicability.
	\item Objectivity.
\end{itemize}

\subsection{Empirical}

To ensure empiricity, the experimental design was formalized as detailed by Field et al \cite{Field2012} with a research question developed and posited as follows; "\textit{Do Swarm Intelligence and Behaviours and systems affect the task performance of multi-agent quadcopter systems in Green Wall Systems}?". The analysis of this affect was undertaken by performing a hypothesis test that further refined the research question into null \ref{hyp:null} and alternate \ref{hyp:alt} hypotheses aforementioned in chapter \ref{objectives}. To perform this analysis, simulator-based experiments were developed based on a designed and consequently proposed GREW-MRS. In order to infer causality, we must set up two scenarios where the independent variable is present and one in which it is absent. These are referred to as the experiment and control conditions respectively. Added care must be taken to ensure both conditions are identical in all senses except for the presence of the cause. This reduces the possibility of \textit{the third variable problem} or \textit{the tertrium quid} where an unidentified, confounding variable effects some unanticipated change in the dependent variable \cite{Field2012}. These latter measures of scenario similarity are covered in \ref{system_design}. In formulating our experiment as thus, the empirical requirement of research experiments is met.

In the main, a leadership-based, robot organisation strategy was employed which has been shown \cite{Dyer2008} to be an effective method in navigational guidance both in the absence and presence of conflicting information. The distinct differences between the control and experimental conditions are listed below:
\begin{itemize}
	\item Navigation path planning.
	\item Local communication.
	\item Global behaviour emergence.
	\item Use of local information.
\end{itemize}

These properties are derived from known swarm robotics characteristics \cite{Dorigo2013}. In navigation path planning, we have centralised and decentralised modes.

\subsubsection{Control Condition}
In the control condition, a naive lawn/seed-spreader path planner \cite{Galceran2013} is implemented along which tasked eyebots can travel and probabilistically act on locally sensed identified targets. The algorithm below was implemented and deployed to each agent in the simulated GREW-MRS. This is shown in Algorithm \ref{alg:con_algo}.

\subsubsection{Experimental Condition}
In the experimental condition, an online Swarm Optimization (SO) algorithm (PSO or ACO) is implemented to generate shortest TSP path solutions of locally communicated target maps. A global map is initialized and made available to each eyebot at start up time to ensure consistent map information is shared between all agents in the collective. Additionally, a probabilistic framework is implemented to control the rest to move and rest to land state transitions of each agent, which in turn is informed by the local sensing of targets and local neighbourhood communication. This is shown in Algorithm \ref{alg:exp_algo}.

\subsection{Measurement}

This paper advances an approach towards the implementation, analysis and evaluation of coverage path planning and coordination control in multi robot systems for Green Wall System maintenance. This analysis and evaluation requires the proposition of validly independent and dependent variables that can be associated with the objective tasks' performance. Statistical samples for both the control and experimental conditions can then be generated. The indepedent/causal variable was characterised as the \textit{usage or non-usage of Swarm Intelligence and Behaviours}. The dependent/outcome variable was selected to be \textit{the simulation-time taken to achieve 90\% target completion coverage}.

Given these variable characterisations, the classification of the independent variable can be seen to be a nominal, two-level measure whereas the dependent variable is a interval measure. Factorial validity of this measure was found to make intuitive sense \cite{Field2012} while its reliability was ensured by performing multiple trial sampling. Given these variable type descriptions, the generation of sample data qualifies the measurement requirement of research experiments. A granular analysis of these measurement variables and their implication for statistical analysis is presented in chapter \ref{evaluation}.

\subsection{Replicability}

Replicability was assured by providing a standardized, script-based method of generating new datasets which is elaborated in \ref{system_design}. This is especially pertinent in generating large simulation datasets where parameter settings can be prone to human error. The developed script-based approach provides a single entry point for trial data generation ensuring all necessary parameters are explicitly set, utilised and stored, thereby guarding against the aforementioned error. Additionally, we provide open access to the dataset generated and analysed in this work to ensure that the parameter-matched experiments can be run and re-analysed by fellow researchers in the field.

\subsection{Objectivity}

The notion of scientific objectivity, while invaluable to the field, is hard to prove empirically as it is multivariate in nature. It assumes that a truth exists independently of inspection or observation which in and of itself has been a tenet of philosophical discourse for millenia. It can, however, be espoused by researchers in their impartiality to the experiments' outcome.

\newpage

\section{System Design} \label{system_design}
The system as presented constitutes a simulation pipeline consisting of the following main subcomponents:
\begin{itemize}
	\item Trial Simulation.
	\item Data Collection, Pre-processing and Analysis.
\end{itemize}

\subsection{Trial Simulation}
There is a recognised lack of reliable and robust swarm-capable simulators \cite{Noronha2016}. Robotics Development Environments (RDEs) have come to play a significant role in robotics research. Despite a lacking availability of systematic RDE evaluation in the literature \cite{Kramer2007}, this work will summarily present comparison criteria key to the viable selection of an autonomous robot simulation environment. In the case of this project, the key RDE characteristics, as defined in \cite{Kramer2007}, were identified to be \textit{Open-source codebase}, \textit{High-fidelity}, \textit{Scalability}, \textit{Multi-Robot Capable}, \textit{Hardware Support} and \textit{3D Capable}. We include an additional criteria; \textit{Active Development}. This is on account of the rather large churn of released RDEs, a key example being Miro \cite{Enderle2001} whose source could not be found online. The proposed RDEs in \cite{Kramer2007} are suitable for an initial selection pool with a number of new releases included that meet the given seletion criteria defined previously. The qualifying RDEs were found to be:
\begin{itemize}
	\item Gazebo \cite{Koenig2004}.
	\item MissionLab \cite{MISSIONLAB}.
	\item ARGoS \cite{Pinciroli2011}.
	\item MORSE \cite{Morse2011}.
\end{itemize}

For this study, trial simulation was performed using the ARGoS simulator, chosen on account of its ability to simulate large numbers (in the thousands) of swarms robots efficiently and flexibly \cite{Pinciroli2014}. The author of the simulator, Prof. Carlo Pinciroli, was found to be actively available on both the development forum page and responded to integration queries as and when needed. In setting up the simulation, the Green Wall System scene environment was purposefully designed to typify a simplified, real-world scenario as shown in Figure \ref{fig:sim_orig_scene}.

\begin{figure}
	\begin{subfigure}[b]{0.6\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/vertical_wall_garden_scene}
		\caption{Simulated Green Wall System Scene}
		\label{fig:sim_orig_scene}
		{The simulated scene run in both control and experiment conditions. The vertical wall is laden with circular (plant) targets with local agents embodied by eye-bot quadcopters}.
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/EyebotCarbonFrame}
		\caption{Eyebot Quadcopter}
		\label{fig:eyebot_hardware}
		{Image of a real-world Eyebot, designed and developed as a robotic agent in the Swarminoid Project \cite{Dorigo2013}}.
	\end{subfigure}
	\caption{Simulator Entities}
	\label{fig:sim_orig}
\end{figure}

The swarminoids' \cite{Dorigo2013} eye-bot quadcopter was selected as this study's simulated aerial platform due to it's established usage in heterogeneous swarm robotics research. By design, they are autonomous flying robots that can attach to an indoor ceiling, and are capable of analysing the environment from a privileged position to collectively gather information inaccessible to terrestrial robots \cite{Dorigo2013}. It is shown in figure \ref{fig:eyebot_hardware} and features the following sensing capabilities:
\begin{itemize}
    \item Custom $360\deg$ pan-tilt camera system, equipped with a 3MP camera.
    \item Optical $360\deg$ infrared environment distance scanner.
    \item Advanced 3D relative positioning sensor for swarm coordination/communication.
    \item Custom 6-Degree of freedom inertial sensing.
    \item Sonar and differential pressure sensors for altitude determination.
    \item Magnetometer for heading determination.
    \item Horizontal RGB led rings (local visual communication).
\end{itemize}

To perform trial simulation, a number of implementation details were essential to developing a suitable, end-to-end simulation pipeline. These include:
\begin{itemize}
	\item Uncertainties.
	\item Cooperative Control.
	\item Coverage Path Planning.
\end{itemize}

\subsubsection{Uncertainties}
Assured robot simulation realism is a growing focus area \cite{Taylor2014} in the dynamic simulator literature with notably recent and advanced examples being AirSim \cite{Shah2018} and Morse \cite{Morse2011} \cite{Lemaignan2014}. To close this simulation-realism gap in ARGoS, a number of independently seeded random generators were required to ensure systematic endogeneous and exogeneous noise and disturbance sources could be appropriately modelled while still ensuring control and experiment similarity in all extraneous senses. The following enumerate all the modelled sources as implemented:

\begin{itemize}
	\item Positioning Noise - Positional noise was modelled as a Gaussian distribution and is statically seeded through all trials. A Kalman Filter is utilised for state prediction whose implementation was based off an openly licensed and available C++ codebase \cite{KALMAN2015}.
	\item Mapping Noise - Mapping noise was modelled as a Gaussian distribution and is statically seeded through all trials. This applies to generation of the global map targets. It is assumed that these target locations are obtained from a previous target mapping stage.
	\item Task Completion - Task Completion Probability was modelled as a Uniform Integer Distribution and is statically seeded through all trials. Task completion is an independent uncertainty whose current probability does not depend on past or future predictions.
	\item Target Classification - Target Classification Probability was modelled as a Uniform Integer Distribution and is statically seeded through all trials. This is a random shuffle stream that is used in the classification of each target found the simulated Green Wall System. This is utilised by the leader agent that performs all target evaluation.
	\item Target Placement - Target Placement was modelled as a Gaussian Distribution and is the only dynamically seeded generator over each trial. This is done to better simulate the fact that for any given number of plant targets on the Green Wall System, a varied number of positional configurations exist.
\end{itemize}

\subsubsection{Cooperative Control}
In \cite{Macas2009}, three methods are identified towards the generation and maintainance of shape formations in autonomous, vehicle-based mobile robots:
\begin{itemize}
	\item Virtual Structure.
	\item Behaviour-based.
	\item Leader-following
\end{itemize}
Through both the control and experimental conditions, a leader-follower strategy, where a target evaluation eyebot agent operated in advance of the slave agents to ensure efficient target classification and task actioning thereafter. In the case of the seed-spreader strategy, agents are strictly concerned with maintaining a virtual leader-based hierarchy to ensure optimal inspection/maintainance coverage. The social-behaviour based strategy is only implemented in the experimental condition as qualified feature of Swarm Robotics (SR). This entailed the sharing of information between the robot collective with each packet sent containing the target id of the current plant target with its' associated task id. Neighbouring agents parse the message and either:

\begin{itemize}
	\item Store the target in its' global map as a task to complete. The agents' moving and landing probabilities are increased and decreased respectively.
	\item Ignore the target if it does not match the agents' task assigned id. The agent's moving and landing probabilities are maintained in this scenario.
\end{itemize}

Swarm robotics systems are characterised by decentralised control, limited communication between robots, use of local information and emergence of global behaviour \cite{Dorigo2013}. An example of this emergence is brought to the fore in simulation where the following was observed:
\begin{itemize}
	\item Agents in the experimental condition are seen to wait until a number of tasked targets are assigned. This wait time is controlled by the probability to move increment value.
	\item Agents in the MRS can move out of the land state to \textit{verify} the state of assigned tasks in an effort to maximise its' landing probability.
\end{itemize}

The ability to inspect and tweak the experimental condition is seen as a valuable feature that enables for a wider emergent behaviour experimentation base. In tandem, this requires a keener understanding of the underlying parameters, possibly necessitating expert domain knowledge to optimally assign values in a problem dependent manner. Bayandir et al \cite{Bayindir2016} provide a review of swarm robotic tasks and viable techniques used to achieve them. To design the organisation systems necessary for guaranteed MRS operation, the task space was delimited to 4 distinct domains:
\begin{itemize}
	\item Evaluation Task.
	\item Water Task.
	\item Nourish Task.
	\item Treatment Task.
\end{itemize}

Due to the relative simplicity of the tasks and social rules implemented in this project, a minimal functionality layer was required. This involved the utilisation of \textit{shared memory} between all locally acting agents and a stigmergy-based approach to validating target status. The latter is an simulation assumption enabled by the real-world use of RFID tag markers. This presents a simplistic avenue to guarantee target completion.

\subsubsection{Coverage Path Planning}
In our work, CPP is achieved by two methods:
\begin{itemize}
	\item In the lawn mover motion, a waypoint decomposition of the target space is performed by iteratively generating coordinate points that ascribe to the defined motion. Here, a number of parameters must be set to control the increment steps necessary in the lateral and longitudinal directions.
	\item In the behaviour-based coordination control, a swarm-inspired neighbour-listening approach is used to generate local task waypoint maps for each slave agent. The leader agent is charged with evaluating each plant target as listed in it’s global map.
\end{itemize}

The CPP problem can be suitably mapped onto a connected graph, \textit{$G = (N, E)$} where each node \textit{$n \in N$} is a target plant position. This connected graph is conveniently solvable by metaheuristic algorithms tuned to find the shortest Hamiltonian path between a pair of nodes.

\paragraph{Discrete Particle Swarm Optimization}
The Particle Swarm Optimization (PSO) metaheuristic algorithm, introduced in 1995 by Kennedy et al \cite{Kennedy1995}. The original formulation was devised for the optimization of continuous non-linear functions, whereas this project required the use of a discretized solver. Whereas the Ant Colony Optimization algorithm was inspired by the social structure of ants, the PSO algorithm is more general in its' assumption of societal paradigms. However, core to its motivating hypothesis was the attempt to model human social behaviour \cite{Kennedy1995}. Phung et al \cite{Phung2017} provide a reference pseudocode implementation from which the implemented C++ PSO optimizer was derived.

\paragraph{Ant Colony Optimization}
The Ant Colony Optimization (ACO) metaheuristic algorithm, was introduced in 1999 by Dorigo et al \cite{Dorigo1999}. They enhance the Simple Ant Colony Optimization (S-ACO) algorithm that is limited to generating solutions to shortest path problems without the ability to apply additional constraints. This is done by the encoding of the whole ant search process as pheromone trails along each graph connection/edge. These pheromone trails are subsummed under a stochastic local decision policy; in the literature, this policy can be modified and adapted for different convergence and solution characteristics. This includes pheromone trail evaporation rates and daemon actions \cite{Dorigo1999}. Dorigo et al \cite{Dorigo1999} provide a reference pseudocode implementation from which the implemented C++ ACO optimizer was derived.


\paragraph{Lawn Sweeping Motion}
Cao et al \cite{Cao1988} introduced a region filling strategy for sweeping operations in a robot lawn mower (RLM), thereby setting the stage for advanced studies into coverage path planning (CPP) strategies \cite{Galceran2013}. In this work, we implement a similar region filling strategy, with one caveat being the lack of obstacle avoidance and replanning. In the implemented C++ Lawn Generation algorithm, an iterative waypoint generation scheme was developed whose horizontal and vertical step parameters dictated the waypoint density of the outputted map. This worked adequately well for our purposes, though it was found that a parameter optimization step would be necessary to tune the waypoint density to the required target number and spread. Alternatively, performing a cellular decomposition of the target space as informed by the positions of the concerned targets would result in an optimal lawn path generation scheme; better amenable to a performance comparison against swarm-inspired approaches as presented here.

\newpage

\subsection{Data Collection, Pre-Processing and Analysis}
The ability to generate and analyse simulation data is cardinal to the evaluation of the works presented in this project. It necessitates the development of a data pipeline that involves the collection, pre-processing and analysis of said data. To do so in an efficiently automated manner, a dynamic shell script was developed to manage both the collection and management of simulation data. This script can be found in this project's shared codebase repository \cite{SWARMCODE} and is named \textit{run.sh}. This script was tested and run on an Ubuntu 16.04 System as well as Window Subsystem for Linux with a number of cross-platform bugs quashed to ensure feature parity. A number of bash script flags are made available to the user to better configure multiple trial runs. These are shown in code snippet \ref{code:script_help}:

\begin{code}
\begin{minted}{bash}
./run.sh usage:
        -a  Select path planning algorithm/strategy (pso, aco or lawn).
        -b  Build the main argos project. Use after editing source files.
        -d  Set the number of drones to place in simulation.
        -e  Set experiment source file. Currently defaults to "main".
        I)  Create experiment environment and install package dependancies.
        -j  Run the jupyter environment.
        -n  Set number of targets/plants to place in simulation.
        N)  Set value range of targets/plants to place in simulation.
        -s  Set the number of independently seeded trials to run.
        -t  Set the target coverage/inspection percentage during trial.
        -v  Enable argos vizualization. Disabled by default for speed.
        h | *)  Print this usage info.
\end{minted}
\captionof{listing}{Script Entrypoint Options}
\label{code:script_help}
\end{code}
\vspace{1cm}

A simple user manual is provided in the linked code repository \cite{SWARMCODE}. The script should first setup the project environment using the \textit{I} flag. An example of a full suite simulation is shown in code snippet \ref{code:run_sim}.

\begin{code}
\begin{minted}{bash}
	sudo ./run.sh -t "0.90" -a "pso aco lawn" -s "10" -n "2 50"
\end{minted}
\captionof{listing}{Full-Suite Simulation Command}
\label{code:run_sim}
\end{code}
\vspace{1cm}

A number of simulation CPP Parameters were set as follows and kept constant for all experiments as shown in table \ref{tab:sim_cpp_params}. For our purposes, these statically set parameters were determined by experimentation and lead to guaranteed target completions thresholds across a wide range of target numbers in simulation. The PSO and ACO parameters...

\bgroup
\def\arraystretch{1.5}% 
\begin{table}[h]
  \centering
  \begin{tabular}{|l|c|c|}
  \hline
  \textbf{Planner} & \textbf{Parameter Name} & \textbf{Parameter Value} \\
  \hline
  \multirow{3}{*}{PSO} & Self Trust & 0.2 \\
	& Past Trust & 0.1 \\
	& Global Trust & 0.7 \\
  \hline
  ACO & Number of Ants & 10 \\
  \hline
  \multirow{3}{*}{LAWN} & Launch Step & 500 \\
	& Horizontal Step & 0.1 \\
	& Vertical Step & 0.1 \\
  \hline
  \end{tabular}
  \caption{Simulation CPP Strategy Parameters}
  \label{tab:sim_cpp_params}
\end{table}
\egroup

Code snippet \ref{code:run_sim} is in fact the very command used to generate the sample dataset provided by this work. The passed flags direct the script to set the target completion threshold at $90\%$, across all CPP strategies (pso, aco and lawn) with 10 independently seeded target trials for a range of 2 to 50 targets in simulation. The script as currently implemented generates a simulation dataset in a CSV formatted text file with CPU and simulation statistics saved to profile logs files. The simulator variables stored are shown in table \ref{tab:csv_params}.

In data analysis, preparing the data for efficient processing is a necessary step. This was found to be especially true for this project given the large memory footprints of the generated datasets. For comparison, the sample dataset has uncompressed memory footprint of 4.2 GigaBytes. For ease of data sharing, this was compressed using standard Linux compression tools. Pre-processing was completed with the help of Pandas \cite{Pandas}, a Python data analysis library. This involved splicing the dataset into its constitient considered strategies (pso, aco and lawn) and making sure to optimize datatypes to their expected range values before storing the resultant subsets as HDF5 dataFrames. This has a significant effect on the storage and loading performance of the dataset resulting in a memory footprint of 2.1 GigaBytes.

The analysis of the dataset was performed in a Jupyter Notebook environment \cite{Jupyter}, a scientific computing tool that has received widespread use and mention in industry and research \cite{Helen2014} \cite{ACM2017}. The codebase sets up an isolated python environment from which it can run the sample Jupyter Notebook \textit{SwarmAnalysis.ipynb}. It can be easily activated by running the command \textit{./run.sh -j} in the projects' root directory over the command line.

\chapter{Evaluation} \label{evaluation}

In Swarm Robotics (SR) research, it is difficult (if not impossible) to directly observe, examine and understand all the collectives' properties and consequent behaviours. Given the latter problem, we resort to collecting random samples from the control and experimental conditions with which we can perform some level of analysis. Hypothesis testing is one such level of analysis that is used to evaluate two mutually exclusive statements about populations to determine which statement is best supported by sample data. These two statements are known as the null hypothesis (\ref{hyp:null2}) and the alternative hypothesis (\ref{hyp:alt2}) with our indepedent/causal variable, a nominal, two-level measure characterised as the \textit{usage or non-usage of Swarm Intelligence and Behaviours}, defining our control and experimental conditions. SciPy \cite{SCIPY}, a python scientific computing library was utilised that features a vast number of statistical utilities that are essential to modern, data-driven research, one of which is a hypothesis testing api and \cite{bmgi} used to better chart the steps taken to perform a hypothesis test.

\begin{hyp}[$H_o$]\label{hyp:null2}
	The mean time-to-threshold in the Lawn strategy is equal to that of the Swarm-inspired strategy.
	The mean time-to-threshold in the Lawn strategy is \textbf{not} equal to that of the Swarm-inspired strategy.
\end{hyp}
	
\begin{hyp}[$H_a$]\label{hyp:alt2}
	We can consider a significant difference between the mean values of the two strategies.
\end{hyp}

 We must firstly determine the specific hypothesis test that would be valid given our dependent/outcome variable, an interval measure defined as \textit{the simulation-time taken to achieve 90\% target completion coverage}. To do so, certain data requirements must be met to properly determine which analysis can be performed. As initially designed, the dependent variable is continuous. However upon a second examination of the data retrieved from our simulation, a notable discrepancy was identified with missing entries found in the dataset. Further investigation revealed a high inflexibililty to environment dynamicity, manifesting as very large changes or hard limit contraventions in our dependent variable as a consequence of varying target position configurations.

 A consequence of this is that while each strategy trial was designed to be independently seeded for multiple iterations and the dependent variable averaged across all iterations, we could not guarantee similar sample sizes across all trials. This maintainance of mutually consistent estimates is a well known problem in the inferential statistics literature, typically solved by weighting procedures \cite{Kalton2003} \cite{Boonstra2004} such as repeated weighting \cite{Renssen2001}. However, additional data modelling steps are required before a valid weighting procedure can be settled upon. A naive approach that involves fixing the target position configuration across simulation trials cannot be guaranteed to produce successful runs in both the control and experimental conditions as well as not accounting for the need for randomly collected samples. Conversely, this project implemented a more valid data integrity check during simulation runtime that re-seeded a new trial iteration when unsuccessful runs occur. Unsuccessful runs were a result of a logical data logging flaw in which the generation of premature target threshold positives led to invalid logging events. The addressing fix implemented hard limits on the logging event manager, set to terminate a running trial when all eye-bots are in the landed state and the simulator has run for an arbitrarily large total of $200,000$ ticks, settled upon by experimentation. This follows from the statistical analysis literature wherein confounding variable effects must be mitigated with sample data randomly collected, conditions which this project reasonably meets. Here, the confounding variable is the variability in the configuration of target positions.

Ultimately, this nuanced dataset validation process was found to be instrumental to our analysis whilst maintaining the random nature of the sampling process required for statistical validity. Having addressed the data domain problem, the next step involved identifying which hypothesis test is applicable to our cleaned data with a hierarchy of common hypothesis tests is shown in figure \ref{fig:hyp_tests}.

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{images/HypothesisTest}
	\caption{Hypothesis Tests}
	\label{fig:hyp_tests}
\end{figure}

Parametric and non-parametric tests make certain assumptions about the sample distributions with the former assuming data normality and homoscedasticity while the latter assumes the opposite. In cases where data normality cannot be guaranteed, parametric tests such as t-tests have been shown to be robust to departures from normality given sufficiently large sample sizes. This affords us some leeway in test selection, but only just so. Additionally, our dependent variable can be seen to be discrete in nature i.e. number of simulation steps. More precisely, it is of interval, count datatype meaning it can only take on non-negative integer values where these numbers arise from counting rather than ranking which calls for a parametric test. In our case, and as recommended in \cite{CountCont}, the dependent variable can however be treated as continuous as it is never near zero and ranges over very large numbers. As such, we can reasonably presume to select the Student's t test, a hypothesis test used to compare the means of the two samples \cite{Donald2008}. The parametric characteristic is preferable on account of the following \cite{Field2012}:
\begin{itemize}
	\item There exist a greater variety of tests available that would allow for a wider experimentation base.
	\item Parametric tests are generally better at identifying experimental effects.
\end{itemize}

There are a number of guidelines that exist in the literature for cases of non-normal data when performing hypothesis tests \cite{MTGuides}:
\begin{itemize}
	\item Two-sample test - Each group should have more than 15 observations.
	\item One-sample test - Each group should have more than 20 observations.
	\item One-way ANOVA - For 2-9 groups, each group should have more than 15 observations. For 10-12 groups, each group should have more than 20 observations.
\end{itemize}

This project presents a sample size of $N=17$ observations, well within the recommended sample size bounds previously highlighted. There are a number of important considerations that must be taken into account when choosing the sample size which is known to have an error effect. There are two general types of errors that lead to false conclusions about our populations:
\begin{itemize}
	\item Type \rom{1} error - known as a false positive; occurs when our test rejects a null hypothesis that is true. The Type \rom{1} error rate equals our significance level/alpha ($\alpha$).
	\item Type \rom{2} error - known as a false negative; occurs when our test fails to reject a null hypothesis that is false. The Type \rom{2} error rate is commonly referred to as the beta ($\beta$) value.
\end{itemize}

The statistical power of a test is the probability that a hypothesis test correctly rejects a null hypothesis and is computed as $1 - \beta$. Generally, small sample sizes, noisy data or small effect sizes tend to reduce the statistical power of tests. As such, we may want to increase the sample size in future studies, but in the literature a \textit{power analysis} is typically used to better inform sample size selection as there is a balance that must be maintained. Increasing the sample size enhances the tests' ability to infer small effects, but this comes at a cost; in our case this cost is largely computational time; it takes a long time to generate large datasets. There also exists a point of diminishing returns where the effect size ceases to grow at which point it looses practical significance. In the main, we would want to collect a sample that is large enough to have sufficient statistical power to detect \textit{meaningful} effect while not being too large to be overly costly/expensive.

Additionally, the sample error, defined as the difference between the sample statistic and the population value, is a metric that must be factored in when deciding when to reject, or fail to reject a null hypothesis. This is because differences observed in the extracted samples might be attributable to the sample error and not a true effect of the population. This is exhibited in the failure to replicate experiment results, a core tenet of good research.

\section{Dataset Generation}\label{dataset-generation}

The run script (\texttt{run.sh}) in the source codes' root directory is the main entrypoint for this project. It has a number of options that can be dynamically set for a wide range of simulation scenarios. This are available for reference by passing the help flag as a parameter.

\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}./run.sh \PYZhy{}h
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
./run.sh usage:
        -a  Select path planning algorithm/strategy (pso, aco or lawn).
        -b  Build the main argos project. Use after editing source files.
        -d  Set the number of drones to place in simulation.
        -e  Set experiment source file. Default: "main".
        I)  Create experiment environment and install package dependancies.
        -j  Run the jupyter environment.
        -m  Set hard-limit for simulation runtime. Default: 20,000
        -n  Set number of targets/plants to place in simulation.
        N)  Set value range of targets/plants to place in simulation.
        -s  Set the number of independently seeded trials to run.
        -t  Set the target coverage/inspection percentage during trial.
        -v  Enable argos vizualization. Disabled by default for speed.
        h | *)  Print this usage info.

\end{Verbatim}

The sample dataset was created with the following settings: - Target Coverage Percentage of 90\% - Across all three path planning algorithms/strategies. - independently seeding 5 random child trials per parent iteration. - Across a range of 1 to 19 targets.

\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}./run.sh \PYZhy{}t \PY{l+s+s2}{\PYZdq{}0.90\PYZdq{}} \PYZhy{}a \PY{l+s+s2}{\PYZdq{}pso aco lawn\PYZdq{}} \PYZhy{}s \PY{l+s+s2}{\PYZdq{}5\PYZdq{}} \PYZhy{}N \PY{l+s+s2}{\PYZdq{}2 19\PYZdq{}}
\end{Verbatim}

\newpage
\section{Pre-process
Dataset}\label{pre-process-dataset}

\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Import the necessary packages.}
\PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
\PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
\PY{k+kn}{from} \PY{n+nn}{math} \PY{k}{import} \PY{n}{sqrt}
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{ttest\PYZus{}ind}
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{t}
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{levene}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{matplotlib} \PY{k}{as} \PY{n+nn}{plt}
\PY{k+kn}{from} \PY{n+nn}{math} \PY{k}{import} \PY{n}{sqrt}
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{api} \PY{k}{as} \PY{n+nn}{sm}
\end{Verbatim}


We first convert the csv dataset into hdf5 format for data storage and loading efficiency, and compute our sample properties thereafter.

\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{chunksize} \PY{o}{=} \PY{l+m+mi}{10} \PY{o}{*}\PY{o}{*} \PY{l+m+mi}{4}
\PY{n}{filename} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{output/data\PYZus{}0.csv}\PY{l+s+s1}{\PYZsq{}}
\PY{n}{headers} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TargetNum}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TargetThresh}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SimStep}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Completed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MinimumHold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LaunchStep}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{InitialRtMProb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtMDelta}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{InitialRtLProb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtLDelta}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MinimumRest}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{InitialMinimumHold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MaximumHold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{GlobalReach}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ProximityThresh}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attitude}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SwarmParticles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SwarmSelfTrust}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SwarmPastTrust}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SwarmGlobalTrust}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SwarmAnts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MappingMean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MappingStdDev}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MappingSeed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtMMin}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtMMax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtMSeed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtLMin}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtLMax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtLSeed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ACOSeed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TaskCompletedMin}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TaskCompletedMax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TaskCompletedSeed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TargetShuffleMin}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TargetShuffleMax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TargetShuffleSeed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{NaiveMapping}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{VStep}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{HStep}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SimStepMax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SimTrialNum}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ArgosSeed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{datatypes} \PY{o}{=} \PY{p}{\PYZob{}}
\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{string\PYZus{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TargetNum}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TargetThresh}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SimStep}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint32}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Completed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint32}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MinimumHold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LaunchStep}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{InitialRtMProb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{float16}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtMDelta}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{float16}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{InitialRtLProb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{float16}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtLDelta}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{float16}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MinimumRest}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{InitialMinimumHold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MaximumHold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{GlobalReach}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{float16}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ProximityThresh}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{float16}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attitude}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{float16}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SwarmParticles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SwarmSelfTrust}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{float16}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SwarmPastTrust}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{float16}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SwarmGlobalTrust}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{float16}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SwarmAnts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MappingMean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{float16}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MappingStdDev}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{float16}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MappingSeed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtMMin}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtMMax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtMSeed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint16}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtLMin}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtLMax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RtLSeed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ACOSeed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TaskCompletedMin}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TaskCompletedMax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TaskCompletedSeed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TargetShuffleMin}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TargetShuffleMax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TargetShuffleSeed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{NaiveMapping}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{VStep}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{float16}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{HStep}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{float16}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SimStepMax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint32}\PY{p}{,}
	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SimTrialNum}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ArgosSeed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}
\PY{p}{\PYZcb{}}
          
\PY{k}{def} \PY{n+nf}{saveAsHDF}\PY{p}{(}\PY{n}{chunk}\PY{p}{)}\PY{p}{:}
	\PY{n}{chunk}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{chunk}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pso}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{to\PYZus{}hdf}\PY{p}{(}
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{output/pso.h5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  \PY{n}{key} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{mode} \PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{a}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb}{format}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{table}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{append} \PY{o}{=} \PY{k+kc}{True}\PY{p}{)}
	\PY{n}{chunk}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{chunk}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{aco}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{to\PYZus{}hdf}\PY{p}{(}
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{output/aco.h5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  \PY{n}{key} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{mode} \PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{a}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb}{format}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{table}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{append} \PY{o}{=} \PY{k+kc}{True}\PY{p}{)}
	\PY{n}{chunk}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{chunk}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lawn}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{to\PYZus{}hdf}\PY{p}{(}
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{output/lawn.h5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  \PY{n}{key} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{mode} \PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{a}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb}{format}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{table}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{append} \PY{o}{=} \PY{k+kc}{True}\PY{p}{)}
          
\PY{k}{for} \PY{n}{chunk} \PY{o+ow}{in} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{,} \PY{n}{chunksize}\PY{o}{=}\PY{n}{chunksize}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n}{datatypes}\PY{p}{)}\PY{p}{:}
         \PY{n}{saveAsHDF}\PY{p}{(}\PY{n}{chunk}\PY{p}{)}
\end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} We then re\PYZhy{}load our categorised hdf5 datasets piecemeal and compute their means.}
\PY{n}{pso} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}hdf}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{output/pso.h5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{aco} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}hdf}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{output/aco.h5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{lawn} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}hdf}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{output/lawn.h5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{means} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pso}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{aco}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lawn}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          
\PY{n}{means}\PY{o}{.}\PY{n}{pso} \PY{o}{=} \PY{n}{pso}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TargetNum}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SimStep}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{means}\PY{o}{.}\PY{n}{aco} \PY{o}{=} \PY{n}{aco}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TargetNum}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SimStep}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{means}\PY{o}{.}\PY{n}{lawn} \PY{o}{=} \PY{n}{lawn}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TargetNum}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SimStep}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
          
\PY{n+nb}{print}\PY{p}{(}\PY{n}{means}\PY{p}{)}
\end{Verbatim}

\newpage
\begin{Verbatim}[commandchars=\\\{\}]
			pso      aco     lawn
	TargetNum                           
	1              2.0      2.0      2.0
	2            547.4    547.2   1108.0
	3            548.6   1733.2   2144.4
	4           5447.0   5447.0   5258.0
	5           4559.4   5573.8  12269.0
	6           4330.0   5025.6  16109.8
	7           5249.6   4908.4  13759.0
	8           4792.2   4798.0  15863.0
	9           3745.4   4769.0  14957.2
	10          6678.8   4761.8  17078.8
	11          5054.0   2106.6  15673.0
	12          2174.2   2168.4  15319.6
	13          5976.8   5991.0  17299.4
	14          5054.4   3224.6  16612.2
	15          6288.8   9220.6  18502.0
	16          3285.6   3285.8  18051.6
	17          8141.4   6227.4  17336.2
	18         14865.2  13041.2  18477.0
	19         16711.4  13027.8  18062.8

\end{Verbatim}

\section{Data Analysis}\label{data-analysis}

We visualize the plots to determine what their distributions may look like.

\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Let\PYZsq{}s plot the mean values of each strategy}
\PY{n}{m\PYZus{}plot} \PY{o}{=} \PY{n}{means}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{kind}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{line}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{style}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{g}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)} 
\PY{n}{m\PYZus{}plot}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Average Strategy Performance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{m\PYZus{}plot}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Plant Target Number}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{m\PYZus{}plot}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Time to Target Threshold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} 
\PY{n}{m\PYZus{}plot\PYZus{}fig} \PY{o}{=} \PY{n}{m\PYZus{}plot}\PY{o}{.}\PY{n}{get\PYZus{}figure}\PY{p}{(}\PY{p}{)}
\PY{n}{m\PYZus{}plot\PYZus{}fig}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thesis/images/means\PYZus{}line\PYZus{}plot.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{bbox\PYZus{}inches}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{images/mean_line_plots}
	\caption{Mean Line Plots}
	\label{fig:meanlineplots}
\end{figure}

We can also plot the strategy performances in bar charts to better infer their distribution.

\begin{Verbatim}[commandchars=\\\{\}]          
\PY{n}{pso\PYZus{}plot} \PY{o}{=} \PY{n}{means}\PY{o}{.}\PY{n}{pso}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{bar}\PY{p}{(}\PY{n}{width}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{pso\PYZus{}plot}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Distribution of PSO Performance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{pso\PYZus{}plot}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Plant Target Number}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{pso\PYZus{}plot}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Time to Target Threshold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{pso\PYZus{}fig} \PY{o}{=} \PY{n}{pso\PYZus{}plot}\PY{o}{.}\PY{n}{get\PYZus{}figure}\PY{p}{(}\PY{p}{)}
\PY{n}{pso\PYZus{}fig}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thesis/images/pso\PYZus{}bar.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{bbox\PYZus{}inches}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
    
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{aco\PYZus{}plot} \PY{o}{=} \PY{n}{means}\PY{o}{.}\PY{n}{aco}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{bar}\PY{p}{(}\PY{n}{width}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{aco\PYZus{}plot}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Distribution of ACO Performance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{aco\PYZus{}plot}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Plant Target Number}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{aco\PYZus{}plot}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Time to Target Threshold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{aco\PYZus{}fig} \PY{o}{=} \PY{n}{aco\PYZus{}plot}\PY{o}{.}\PY{n}{get\PYZus{}figure}\PY{p}{(}\PY{p}{)}
\PY{n}{aco\PYZus{}fig}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thesis/images/aco\PYZus{}bar.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{bbox\PYZus{}inches}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{lawn\PYZus{}plot} \PY{o}{=} \PY{n}{means}\PY{o}{.}\PY{n}{lawn}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{bar}\PY{p}{(}\PY{n}{width}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{lawn\PYZus{}plot}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Distribution of Lawn Performance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{lawn\PYZus{}plot}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Plant Target Number}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{lawn\PYZus{}plot}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Time to Target Threshold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{lawn\PYZus{}fig} \PY{o}{=} \PY{n}{lawn\PYZus{}plot}\PY{o}{.}\PY{n}{get\PYZus{}figure}\PY{p}{(}\PY{p}{)}
\PY{n}{lawn\PYZus{}fig}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thesis/images/lawn\PYZus{}bar.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{bbox\PYZus{}inches}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

\begin{figure}[H]
	\begin{subfigure}[h]{0.4\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/pso_bar}
		\caption{Bar Plot of PSO Data}
		\label{fig:psobar}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.4\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/aco_bar}
		\caption{Bar Plot of ACO Data}
		\label{fig:acobar}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.4\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/lawn_bar}
		\caption{Bar Plot of Lawn Data}
		\label{fig:lawnbar}
	\end{subfigure}
	\caption{Bar Plots}
	\label{fig:barplots}
\end{figure}

As can be seen in the figure above, there is a marked variability in the mean performance of the strategies, but a generally linear trend can be assumed to be present.

\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} We can comparatively visualize the distributions using a box plot}
\PY{n}{m\PYZus{}plot\PYZus{}box} \PY{o}{=} \PY{n}{means}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{box}\PY{p}{(}\PY{p}{)}
\PY{n}{m\PYZus{}plot\PYZus{}box}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Strategy Distributions}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{m\PYZus{}plot\PYZus{}box}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Time to Target Threshold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{m\PYZus{}plot\PYZus{}box\PYZus{}fig} \PY{o}{=} \PY{n}{m\PYZus{}plot\PYZus{}box}\PY{o}{.}\PY{n}{get\PYZus{}figure}\PY{p}{(}\PY{p}{)}
\PY{n}{m\PYZus{}plot\PYZus{}box\PYZus{}fig}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thesis/images/mean\PYZus{}box\PYZus{}plots.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{bbox\PYZus{}inches}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{images/mean_box_plots}
	\caption{Mean Box Plots}
	\label{fig:meanboxplots}
\end{figure}

We then identify the shape of our data distributions using Quantile-Quantile (Q-Q) plots. In the Q-Q plots below, the quantiles of our sample distributions are plotted against quantiles of a normal distribution as a scatter plot.

\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} We use statsmodels qqplot feature to test our distributions.}
\PY{n}{pso\PYZus{}qq\PYZus{}fig} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{qqplot}\PY{p}{(}\PY{n}{means}\PY{o}{.}\PY{n}{pso}\PY{p}{,} \PY{n}{line}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{45}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fit}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{aco\PYZus{}qq\PYZus{}fig} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{qqplot}\PY{p}{(}\PY{n}{means}\PY{o}{.}\PY{n}{aco}\PY{p}{,} \PY{n}{line}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{45}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fit}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{lawn\PYZus{}qq\PYZus{}fig} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{qqplot}\PY{p}{(}\PY{n}{means}\PY{o}{.}\PY{n}{lawn}\PY{p}{,} \PY{n}{line}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{45}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fit}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
          
\PY{n}{pso\PYZus{}qq\PYZus{}fig}\PY{o}{.}\PY{n}{suptitle}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Quantile Plot of PSO Data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{aco\PYZus{}qq\PYZus{}fig}\PY{o}{.}\PY{n}{suptitle}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Quantile Plot of ACO Data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{lawn\PYZus{}qq\PYZus{}fig}\PY{o}{.}\PY{n}{suptitle}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Quantile Plot of Lawn Data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
\PY{n}{pso\PYZus{}qq\PYZus{}fig}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thesis/images/pso\PYZus{}qq.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{bbox\PYZus{}inches}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{aco\PYZus{}qq\PYZus{}fig}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thesis/images/aco\PYZus{}qq.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{bbox\PYZus{}inches}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{lawn\PYZus{}qq\PYZus{}fig}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thesis/images/lawn\PYZus{}qq.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{bbox\PYZus{}inches}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

\begin{figure}[H]
	\begin{subfigure}[h]{0.4\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/pso_qq}
		\caption{Q-Q Plot of PSO Data}
		\label{fig:qqpso}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.4\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/aco_qq}
		\caption{Q-Q Plot of ACO Data}
		\label{fig:qqaco}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.4\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/lawn_log_qq}
		\caption{Q-Q Plot of Lawn Data}
		\label{fig:qqlawn}
	\end{subfigure}
	\caption{Q-Q Plots}
	\label{fig:qqplot}
\end{figure}

It can be visually estimated that our data is normally distributed as
the presented datasets generally follow their plotted diagonal lines. We
could additionally use Scipys' normaltest utility to determine this
normality, noting that the kurtosis test is only valid for sample sizes
greater than or equal to 20.

\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{ntest\PYZus{}pso} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{normaltest}\PY{p}{(}\PY{n}{means}\PY{o}{.}\PY{n}{pso}\PY{p}{)}
\PY{n}{ntest\PYZus{}aco} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{normaltest}\PY{p}{(}\PY{n}{means}\PY{o}{.}\PY{n}{aco}\PY{p}{)}
\PY{n}{ntest\PYZus{}lawn} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{normaltest}\PY{p}{(}\PY{n}{means}\PY{o}{.}\PY{n}{lawn}\PY{p}{)}
          
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The results of the normality tests are: }\PY{l+s+se}{\PYZbs{}n}
	\PY{l+s+s1}{PSO: \PYZhy{}\PYZgt{} tc\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{ tp\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+se}{\PYZbs{}n}
	\PY{l+s+s1}{ACO: \PYZhy{}\PYZgt{} tc\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{ tp\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+se}{\PYZbs{}n}
	\PY{l+s+s1}{LAWN: \PYZhy{}\PYZgt{} tc\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{ tp\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}
	\PY{n}{ntest\PYZus{}pso}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{n}{ntest\PYZus{}pso}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
	\PY{n}{ntest\PYZus{}aco}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{n}{ntest\PYZus{}aco}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
	\PY{n}{ntest\PYZus{}lawn}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{n}{ntest\PYZus{}lawn}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
The results of the normality tests are: 
PSO: -> tc-value = 11.144 tp-value = 0.004 
ACO: -> tc-value = 5.515 tp-value = 0.063 
LAWN: -> tc-value = 6.670 tp-value = 0.036

\end{Verbatim}

Before we can evaluate the result of this normality test, we must define
our significance level (\(\alpha\)) that specifies the probability of
rejecting the null hypothesis when it is actually true. In this
experiment, we elect to set the significance level of the statistical
test to 0.05 as is common in the literature. The goal of a statistical
test is to try and reject the null hypothesis.

We can now evaluate the result of our algorithmic normality test which
returned p-values lower than our alpha level (0.05), indicating a
rejection of the null hypothesis that the distributions are normal.
However, the sample dataset generated only has \(n=19\) and was surmised
to have skewed our tepid normality results as evidenced in the api
output. If normality was not proveable in the exact sense, we could
perform log, square root, or inverse transformations on our original
data which \textbf{may} have led to better approximations to the
normal distribution.

\newpage
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} We could perform a log transformation in the event that our original data proved non\PYZhy{}normal.}
\PY{c+c1}{\PYZsh{} This doesn\PYZsq{}t guarantee normality, but is merely a technique used in the literature.}
\PY{n}{pso\PYZus{}qq\PYZus{}fig} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{qqplot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{means}\PY{o}{.}\PY{n}{pso}\PY{p}{)}\PY{p}{,} \PY{n}{line}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{45}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fit}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{aco\PYZus{}qq\PYZus{}fig} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{qqplot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{means}\PY{o}{.}\PY{n}{aco}\PY{p}{)}\PY{p}{,} \PY{n}{line}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{45}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fit}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{lawn\PYZus{}qq\PYZus{}fig} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{qqplot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{means}\PY{o}{.}\PY{n}{lawn}\PY{p}{)}\PY{p}{,} \PY{n}{line}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{45}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fit}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{pso\PYZus{}qq\PYZus{}fig}\PY{o}{.}\PY{n}{suptitle}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Quantile Plot of Log PSO Data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{aco\PYZus{}qq\PYZus{}fig}\PY{o}{.}\PY{n}{suptitle}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Quantile Plot of Log ACO Data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{lawn\PYZus{}qq\PYZus{}fig}\PY{o}{.}\PY{n}{suptitle}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Quantile Plot of Log Lawn Data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
\PY{n}{pso\PYZus{}qq\PYZus{}fig}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thesis/images/pso\PYZus{}log\PYZus{}qq.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{bbox\PYZus{}inches}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{aco\PYZus{}qq\PYZus{}fig}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thesis/images/aco\PYZus{}log\PYZus{}qq.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{bbox\PYZus{}inches}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{lawn\PYZus{}qq\PYZus{}fig}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thesis/images/lawn\PYZus{}log\PYZus{}qq.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{bbox\PYZus{}inches}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

\begin{figure}[H]
	\begin{subfigure}[h]{0.4\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/pso_log_qq}
		\caption{Q-Q Log Plot of PSO Data}
		\label{fig:qqlogpso}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.4\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/aco_log_qq}
		\caption{Q-Q Log Plot of ACO Data}
		\label{fig:qqlogaco}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.4\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/lawn_log_qq}
		\caption{Q-Q Log Plot of Lawn Data}
		\label{fig:qqloglawn}
	\end{subfigure}
	\caption{Q-Q Log Plots}
	\label{fig:qqlogplot}
\end{figure}

We have proven normality and now must prove homoscedasticity. A number of tests exist to perform this check, including: - Bartlett's Test (parametric) - Levene's Test (parametric) - Fligner's Test (non-parametric)

They exhibit decreasing sensitivity to strong departures from normality with Fligner's being the most robust. We limit ourselves to these tests as they have implementations in the SciPy Python library. We take a middle-of-the-road approach and go for Levene's Test as computed below.

\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{lev\PYZus{}pa} \PY{o}{=} \PY{n}{levene}\PY{p}{(}\PY{n}{means}\PY{o}{.}\PY{n}{pso}\PY{p}{,}\PY{n}{means}\PY{o}{.}\PY{n}{aco}\PY{p}{)}
\PY{n}{lev\PYZus{}pl} \PY{o}{=} \PY{n}{levene}\PY{p}{(}\PY{n}{means}\PY{o}{.}\PY{n}{pso}\PY{p}{,}\PY{n}{means}\PY{o}{.}\PY{n}{lawn}\PY{p}{)}
\PY{n}{lev\PYZus{}al} \PY{o}{=} \PY{n}{levene}\PY{p}{(}\PY{n}{means}\PY{o}{.}\PY{n}{aco}\PY{p}{,}\PY{n}{means}\PY{o}{.}\PY{n}{lawn}\PY{p}{)}
          
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The results of the homoscedasticity tests are: }\PY{l+s+se}{\PYZbs{}n}
	\PY{l+s+s1}{PSO: \PYZhy{}\PYZgt{} tw\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{ tp\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+se}{\PYZbs{}n}
	\PY{l+s+s1}{ACO: \PYZhy{}\PYZgt{} tw\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{ tp\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+se}{\PYZbs{}n}
	\PY{l+s+s1}{LAWN: \PYZhy{}\PYZgt{} tw\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{ tp\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}
	\PY{n}{lev\PYZus{}pa}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{n}{lev\PYZus{}pa}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
	\PY{n}{lev\PYZus{}pl}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{n}{lev\PYZus{}pl}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
	\PY{n}{lev\PYZus{}al}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{n}{lev\PYZus{}al}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
The results of the homoscedasticity tests are: 
PSO: -> tw-value = 0.063 tp-value = 0.803 
ACO: -> tw-value = 0.960 tp-value = 0.334 
LAWN: -> tw-value = 1.475 tp-value = 0.232

\end{Verbatim}

As can be seen in the above result, our homoscedasticity test p-values
are higher than our alpha level (0.05) which means we have failed to
reject the null hypothesis that the distributions exhibit equal
variances. If homoscedasticity could not be determinably proven, we
could elect to use Welsch's t-Test that works better with unequal sample
variances. Alternatively, we could perform a variable transformation
such as a Box-Cox transformation.

We can now perform our t-test, where sample independance is assured on
account of the simulation random-trialling mentioned previously. We
shall use the independent, two-sample t-test as shown below:

\section{Hypothesis Test}\label{hypothesis-test}

\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Run independent two\PYZhy{}sample, t\PYZhy{}tests}
\PY{n}{ind\PYZus{}t\PYZus{}test\PYZus{}pa} \PY{o}{=} \PY{n}{ttest\PYZus{}ind}\PY{p}{(}\PY{n}{means}\PY{o}{.}\PY{n}{pso}\PY{p}{,}\PY{n}{means}\PY{o}{.}\PY{n}{aco}\PY{p}{)}
\PY{n}{ind\PYZus{}t\PYZus{}test\PYZus{}pl} \PY{o}{=} \PY{n}{ttest\PYZus{}ind}\PY{p}{(}\PY{n}{means}\PY{o}{.}\PY{n}{pso}\PY{p}{,}\PY{n}{means}\PY{o}{.}\PY{n}{lawn}\PY{p}{)}
\PY{n}{ind\PYZus{}t\PYZus{}test\PYZus{}al} \PY{o}{=} \PY{n}{ttest\PYZus{}ind}\PY{p}{(}\PY{n}{means}\PY{o}{.}\PY{n}{aco}\PY{p}{,}\PY{n}{means}\PY{o}{.}\PY{n}{lawn}\PY{p}{)}
          
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The results of the independent t\PYZhy{}tests are: }
	\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{PSO:ACO \PYZhy{}\PYZgt{} tt\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{ tp\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+se}{\PYZbs{}n}
	\PY{l+s+s1}{PSO:LAWN \PYZhy{}\PYZgt{} tt\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{ tp\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+se}{\PYZbs{}n}
	\PY{l+s+s1}{ACO:LAWN \PYZhy{}\PYZgt{} tt\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{ tp\PYZhy{}value = }\PY{l+s+si}{\PYZob{}:4.3f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}
	\PY{n}{ind\PYZus{}t\PYZus{}test\PYZus{}pa}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{n}{ind\PYZus{}t\PYZus{}test\PYZus{}pa}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
	\PY{n}{ind\PYZus{}t\PYZus{}test\PYZus{}pl}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{n}{ind\PYZus{}t\PYZus{}test\PYZus{}pl}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
	\PY{n}{ind\PYZus{}t\PYZus{}test\PYZus{}al}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{n}{ind\PYZus{}t\PYZus{}test\PYZus{}al}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
	\PY{p}{)}
\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
The results of the independent t-tests are: 
PSO:ACO -> tt-value = 0.315 tp-value = 0.755 
PSO:LAWN -> tt-value = -4.577 tp-value = 0.000 
ACO:LAWN -> tt-value = -5.051 tp-value = 0.000

\end{Verbatim}

    For completeness, we performed a t-test on our pso and aco samples and
got a p-value of \textasciitilde{}0.755, indicating that there is no
statistically significant difference between the two means. More
interestingly though, and of central importance to this work, we have
p-values of \textless{} \(\alpha\) (0.05) for the pso-lawn and aco-lawn
tests, which is an indication of statistically significant difference
between their means. This means we can assuredly reject our null
hypothesis in these scenarios.


\chapter{Conclusion} \label{conclusion}
A more robust and flexible approach utilising the Maximum Likelihood Estimation (MLE) of trial durations was considered and premised to be better placed towards stemming this problem in a more \textit{realistic} fashion. Practically, this enhancement would allow for local agents to probabilitically posit how long the trial is expected to run and at which point to determinably \textit{give up} on local or global objectives. Plant configuration was found to be a confounding variable whose effect was mitigated through re-trials.

If it is something other than binary and if you are really worried – run the t-test and then run the Wilcoxon-Mann-Whitney on the same data and see what you see. The t-test is robust with respect to non-normality but if the data gets too extreme the test can fail to detect a difference in mean location when one exists. The Wilcoxon works under all conditions that would be appropriate for a t-test but it does a better job (has higher power) in cases of extreme asymmetry.

An interesting investigation would be to analyse the CPU load of each trial to analyse strategy performance from a computational standpoint.

Optimization of CPP Strategy Parameters. Future work into leaderless, self-organisation strategies with greater swarm sizes. The former can be achieved via agent roaming procedures that incorporate random walk behaviour with swarm cohesion implemented through Leinard-Jones potentials between agents.
Contributions include a programmatic framework for the generation of simulation data suitable for biological statistical analysis. The need for benchmark datasets in the field is a noted need and it is hoped that added effort is placed towards the release of standardised benchmarking sets.
Established path planners such as Open Motion Planning Library (OMPL) \cite{Sucan2012} should be considered for enhanced validity in comperative analyses. Further, higher order models of the quadcopter and external disturbances such as wind should be considered to enhance simulator realism. Higher order models are possible employing techniques to generating models learned from flight data \cite{Symington2014} whereas robust wind models such as the Dryden wind turbulence model \cite{Dryden} could be included. Collision detection and obstacle avaoidance with 3D-capable metaheuristic planners. Techniques and approaches to parameter optimisation and social learning such as genetic programming or neural networks are high potential, interest areas that would be considered to augment this work in future.
A standardised metaheuristic optimization algorithm library such as \cite{James2018} and a wider variety state prediction techniques such as probabilistic smoothing.
SLAM Mapping of targets.
Multi-objective TSP.
Enhanced local communication with the ring leds.
Implement time estimation techniques to vary holding times.
A dataset repository of similarly generated simulation data with a standardised scientific toolkit, an example of which is PySwarms \cite{James2018}.
There is still much to be desired in the terminology and frameworks available in literature.
As explained in the introduction of \cite{Phung2017}, Implement the DPSO in a GPU-based framework so that the computational time can be significantly reduced while keeping the hardware requirement unchanged.
A better integrated simulator such as MORSE that utilises Blender as its' 3D modelling engine would allow for more visually realistic scenes. Alternatively, AirSim, a recently released autonomous vehicle simulation platform could be used. This would open the field to novel behaviour modelling approaches via deep learning, a field in recent resurgence due to enhanced GPU computing capabilities and access to swaths of training data.
Studies in to the response of the MRS to adaptivity and fault tolerance (Iocchi2001).

As previously mentioned, this work makes the following contributions to the field:

\begin{itemize}
	\item A novel approach to comparatively evaluate the performance of GREW-MRS strategies and implementations. The application of statistical testing is also introduced with novel measurement variables proposed for wider consideration. Data generation is addressed with appropriately developed tooling provided.
	\item A novel and simple simulation pipeline with code made freely available. This works' software repository is made freely available and is scripted as an ARGoS experiment that is dynamically configured with the help of a shell script. It can be found at \url{https://github.com/wndaiga/swarm_ucl} \cite{SWARMCODE}.
	\item A sample dataset of 10 independently and randomly seeded simulation trials over a range of Green Wall target/plant numbers (2-50).
\end{itemize}

It is hoped that this research output proves beneficial to fellow Swarm roboticists towards the advancement of these nascent but rapidly growing and promising fields.

\bibliographystyle{plain}
\bibliography{references/Library,references/Misc}

\newpage

\begin{appendices}

\chapter{CSV Dataset}
\newgeometry{left=0.1cm,right=0.1cm}
\begin{table}
	\begin{center}
		\footnotesize
		\begin{tabular}{|l|c|c|}
		\hline
		\textbf{Parameter} & \textbf{Description} & \textbf{DataType} \\
		\hline
		Type & Indicates the CPP strategy & string \\
		TargetNum & Indicates the total number of targets in simulation & uint8 \\
		TargetThresh & Indicates the computed target completion threshold & uint8 \\
		SimStep & Simulation time step & uint32 \\
		Completed & Number of targets marked as attended & uint32 \\
		MinimumHold & Minimum simulation time that agents must wait in hold state & uint8 \\
		LaunchStep & Minimum simulation time that leader agent must wait before launching (only used in lawn strategy) & uint8 \\
		InitialRtMProb & Initial probability that the leader agent will move from rest to move state & float16 \\
		RtMDelta & Delta value used to modify the probability that the leader agent will move from rest to move state & float16 \\
		InitialRtLProb & Initial probability that the leader agent will move from rest to land state & float16 \\
		RtLDelta  & Delta value used to modify the probability that the leader agent will move from rest to land state & float16 \\
		MinimumRest & Minimum simulation time that agents must wait in rest state & uint8 \\
		InitialMinimumHold & Initial minimum simulation time that agents must wait in hold state & uint8 \\
		MaximumHold  & Maximum simulation time that agents can wait in hold state & uint8 \\
		GlobalReach & Mean distance to wall that the collective must maintain & float16 \\
		ProximityThresh & Minimum positional distance error & float16 \\
		Attitude & Height above targets that leader agent must maintain & float16 \\
		SwarmParticles & PSO parameter to set the number of particles & uint8 \\
		SwarmSelfTrust & PSO parameter to set the particles' current solution weight value & float16 \\
		SwarmPastTrust & PSO parameter to set the particles' past solution weight value & float16 \\
		SwarmGlobalTrust & PSO parameter to set the particles' swarm solution weight value & float16 \\
		SwarmAnts & ACO parameter to set the number of ants in colony & uint8 \\
		MappingMean & Mapping, gaussian distribution mean & float16 \\
		MappingStdDev & Mapping, gaussian distribution standard deviation & float16 \\
		MappingSeed & Mapping, gaussian distribution seed & uint8 \\
		RtMMin & Rest to move, uniform integer distribution min & uint8 \\
		RtMMax & Rest to move, uniform integer distribution max & uint8 \\
		RtMSeed & Rest to move, uniform integer distribution seed & uint16 \\
		RtLMin & Rest to land, uniform integer distribution min & uint8 \\
		RtLMax & Rest to land, uniform integer distribution max & uint8 \\
		RtLSeed & Rest to land, uniform integer distribution seed & uint8 \\
		ACOSeed & ACO Optimizer seed value & uint8 \\
		TaskCompletedMin & Task completion, uniform integer distribution min & uint8 \\
		TaskCompletedMax & Task completion, uniform integer distribution max & uint8 \\
		TaskCompletedSeed & Task completion, uniform integer distribution seed & uint8 \\
		TargetShuffleMin & Target shuffle, uniform integer distribution min & uint8 \\
		TargetShuffleMax & Target shuffle, uniform integer distribution max & uint8 \\
		TargetShuffleSeed & Target shuffle, uniform integer distribution seed & uint8 \\
		NaiveMapping & Target mapping scheme (not fully implemented) & uint8 \\
		VStep & Vertical step used in lawn strategy & float16 \\
		HStep & Horizontal step used in lawn strategy & float16 \\
		SimStepMax & Maximum number of simulation steps before trial prematurely terminates & uint32 \\
		SimTrialNum & The number of seed iterations per trial & uint8 \\
		ArgosSeed  & Argos seed (configures the placement of targets) & uint8 \\
		\hline
		\end{tabular}
	\end{center}
	\caption{CSV Dataset Parameters}\label{tab:csv_params}
\end{table}
\restoregeometry
\chapter{Control Condition Algorithm}
\begin{algorithm}
	\caption{Control Condition Algorithm}
	\label{alg:con_algo}
	\begin{algorithmic}[1]
		\Procedure{ExperimentSimulation} {} \Comment Simulation Entry Point
			\While{$termination\_criteria\_not\_satisfied$}
				\State \textsc{Initialize};
				\State \textsc{CoordinationStrategy};
			\EndWhile
		\EndProcedure
		\\
		\Procedure{Initialize}{}
			\If{$System\_Initialized \neq TRUE$}
				\State $Map_{global} \gets Ordered\_Lawn\_Path\_Waypoints()$; \Comment No Path Optimization
				\State $Waypoint_{current} \gets 0$;
				\State $System\_Initialized = TRUE$
			\EndIf
		\EndProcedure
		\\
		\Procedure{CoordinationStrategy}{}
			\State $Map_{local} = Map_{global}$;
			\If{$Probability_{move} \geq Random_{move}$}
				\State Move to $Waypoint_{current}$;
				\If{$Target_{nearest} \in Map_{local}$  and is unattended}
					\If{$Probability_{completion} = 1$}
						\State Update $Map_{global}$; \Comment Update Target Metadata
						\State $Waypoint_{current} \gets Waypoint_{current} + 1$;
					\Else
						\State Hold;
					\EndIf
				\ElsIf{$Target_{nearest}$ is attended}
					\State $Probability_{land} \gets Probability_{land} + Probability_{land\_increment}$;
					\State $Probability_{move} \gets Probability_{move} - Probability_{move\_increment}$;
				\EndIf
			\ElsIf{$Probability_{land} \geq Random_{land}$}
				\State Land;
			\Else
				\State Rest;
			\EndIf
		\EndProcedure
	\end{algorithmic}
\end{algorithm}
\chapter{Experimental Condition Algorithm}
\begin{algorithm}
	\caption{Experimental Condition Algorithm}
	\label{alg:exp_algo}
	\begin{algorithmic}[1]
		\Procedure{ExperimentSimulation} {} \Comment Simulation Entry Point
			\While{$termination\_criteria\_not\_satisfied$}
				\State \textsc{Initialize};
				\State \textsc{SocialRule};
				\State \textsc{CoordinationStrategy};
			\EndWhile
		\EndProcedure
		\\
		\Procedure{Initialize}{}
			\If{$System\_Initialized \neq TRUE$}
				\State $Map_{global} \gets Path\_Optimized\_Targets()$; \Comment Metaheuristic Optimization
				\State $Waypoint_{current} \gets 0$;
				\State $System\_Initialized = TRUE$
			\EndIf
		\EndProcedure
		\\
		\Procedure{SocialRule}{}
			\If{$message\_recieved \neq NULL$}
				\If{$message\_contains\_attended\_task$}
					\State $Probability_{land} \gets Probability_{land} + Probability_{land\_increment}$;
					\State $Probability_{move} \gets Probability_{move} - Probability_{move\_increment}$;
				\ElsIf{$message\_contains\_assigned\_task$}
					\State $Probability_{land} \gets Probability_{land} - Probability_{land\_increment}$;
					\State $Probability_{move} \gets Probability_{move} + Probability_{move\_increment}$;
				\EndIf
			\EndIf
		\EndProcedure
		\\
		\Procedure{CoordinationStrategy}{}
			\If{$Probability_{move} \geq Random_{move}$}
				\State $Map_{local} \gets Path\_Optimized\_Assigned\_Targets()$; \Comment Metaheuristic Optimization
				\State Move to $Waypoint_{current}$;
				\If{$Target_{nearest} \in Map_{local}$ and is unattended}
					\If{$Probability_{completion} = 1$}
						\State Update $Map_{global}$; \Comment Update Target Metadata
						\State $Waypoint_{current} \gets Waypoint_{current} + 1$;
					\Else
						\State Hold;
					\EndIf
				\ElsIf{$Target_{nearest}$ is attended}
					\State $Probability_{land} \gets Probability_{land} + Probability_{land\_increment}$;
					\State $Probability_{move} \gets Probability_{move} - Probability_{move\_increment}$;
				\EndIf
			\ElsIf{$Probability_{land} \geq Random_{land}$}
				\State Land;
			\Else
				\State Rest;
			\EndIf
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

\end{appendices}

\end{document}
