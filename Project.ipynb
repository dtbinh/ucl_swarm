{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GREW-MRS Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Run Full-Suite Simulation Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The run script is the main entrypoint for this project. It has a number of options that can be dynamically set for a wide range of simulation scenarios. This are available for reference by passing the help flag as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!./run.sh -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dataset with the following settings:\n",
    "- Target Coverage Percentage of 90%\n",
    "- Across all three path planning algorithms/strategies.\n",
    "- Independantly seeding 3 random child trials per parent iteration.\n",
    "- With a target/plant value range of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo -S ./run.sh -t \"0.90\" -a \"aco\" -s 1 -n \"100\" -v < pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and Pre-process Simulation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Independant Student's t-test to determine whether the difference between our **UAV-MRS** simulation datasets is significant. We first import the necessary python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from math import sqrt\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the csv dataset into hdf5 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10 ** 4\n",
    "filename = 'sample/data_0.csv'\n",
    "headers = ['Type','TargetNum','TargetThresh','Step','Completed',\n",
    "         'X','Y','Z','RtMProb','RtLProb','MinimumHold','LaunchStep',\n",
    "         'InitialRtMProb','RtMDelta','InitialRtLProb','RtLDelta',\n",
    "         'MinimumRest','InitialMinimumHold','MaximumHold','GlobalReach',\n",
    "         'ProximityThresh','Attitude','SwarmParticles','SwarmSelfTrust',\n",
    "         'SwarmPastTrust','SwarmGlobalTrust','SwarmAnts','MappingMean',\n",
    "         'MappingStdDev','MappingSeed','RtMMin','RtMMax','RtMSeed','RtLMin',\n",
    "         'RtLMax','RtLSeed','ACOSeed','TaskCompletedMin','TaskCompletedMax',\n",
    "         'TaskCompletedSeed','TargetShuffleMin','TargetShuffleMax',\n",
    "         'TargetShuffleSeed','NaiveMapping','VStep','HStep','ArgosSeed']\n",
    "\n",
    "datatypes={\n",
    "    'Type':np.string_,'TargetNum':np.uint8,'TargetThresh':np.uint8,'Step':np.uint32,'Completed':np.uint8,\n",
    "    'X':np.float16,'Y':np.float16,'Z':np.float16,'RtMProb':np.float16,'RtLProb':np.float16,'MinimumHold':np.uint8,'LaunchStep':np.uint8,\n",
    "    'InitialRtMProb':np.float16,'RtMDelta':np.float16,'InitialRtLProb':np.float16,'RtLDelta':np.float16,\n",
    "    'MinimumRest':np.uint8,'InitialMinimumHold':np.uint8,'MaximumHold':np.uint8,'GlobalReach':np.float16,\n",
    "    'ProximityThresh':np.float16,'Attitude':np.float16,'SwarmParticles':np.uint8,'SwarmSelfTrust':np.float16,\n",
    "    'SwarmPastTrust':np.float16,'SwarmGlobalTrust':np.float16,'SwarmAnts':np.uint8,'MappingMean':np.float16,\n",
    "    'MappingStdDev':np.float16,'MappingSeed':np.uint8,'RtMMin':np.uint8,'RtMMax':np.uint8,'RtMSeed':np.uint16,'RtLMin':np.uint8,\n",
    "    'RtLMax':np.uint8,'RtLSeed':np.uint8,'ACOSeed':np.uint8,'TaskCompletedMin':np.uint8,'TaskCompletedMax':np.uint8,\n",
    "    'TaskCompletedSeed':np.uint8,'TargetShuffleMin':np.uint8,'TargetShuffleMax':np.uint8,\n",
    "    'TargetShuffleSeed':np.uint8,'NaiveMapping':np.string_,'VStep':np.float16,'HStep':np.float16,'ArgosSeed':np.uint8\n",
    "}\n",
    "\n",
    "def saveAsHDF(chunk):\n",
    "    chunk.loc[chunk['Type'] == 'pso'].to_hdf('sample/pso.h5',  key = 'data', mode ='a', format='table', append = True)\n",
    "    chunk.loc[chunk['Type'] == 'aco'].to_hdf('sample/aco.h5',  key = 'data', mode ='a', format='table', append = True)\n",
    "    chunk.loc[chunk['Type'] == 'lawn'].to_hdf('sample/lawn.h5',  key = 'data', mode ='a', format='table', append = True)\n",
    "\n",
    "for chunk in pd.read_csv(filename, chunksize=chunksize, dtype=datatypes):\n",
    "    saveAsHDF(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load our categorised hdf5 datasets piecemeal and compute their means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the pso means first\n",
    "pso_f = pd.read_hdf('sample/preprocessed/pso.h5', 'data')\n",
    "pso_target_thresh = pso_f.groupby('TargetNum', as_index=False).apply(lambda row: row[row['Completed'] == row['TargetThresh']])\n",
    "pso_step_means = pso_target_thresh.groupby('ArgosSeed').head(1).groupby('TargetNum')['Step'].mean()\n",
    "\n",
    "del pso_f, pso_target_thresh\n",
    "\n",
    "print(pso_step_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the aco means\n",
    "aco_f = pd.read_hdf('sample/preprocessed/aco.h5', 'data')\n",
    "aco_target_thresh = aco_f.groupby('TargetNum', as_index=False).apply(lambda row: row[row['Completed'] == row['TargetThresh']])\n",
    "aco_step_means = aco_target_thresh.groupby('ArgosSeed').head(1).groupby('TargetNum')['Step'].mean()\n",
    "\n",
    "del aco_f, aco_target_thresh\n",
    "\n",
    "print(aco_step_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the lawns means\n",
    "lawn_f = pd.read_hdf('sample/lawn.h5', 'data')\n",
    "lawn_target_thresh = lawn_f.groupby('TargetNum', as_index=False).apply(lambda row: row[row['Completed'] == row['TargetThresh']])\n",
    "lawn_step_means = lawn_target_thresh.groupby('ArgosSeed').head(1).groupby('TargetNum')['Step'].mean()\n",
    "\n",
    "del lawn_f, lawn_target_thresh\n",
    "\n",
    "print(lawn_step_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate all the computed means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup = pd.HDFStore('sample/backup.h5')\n",
    "\n",
    "# means = backup['means']\n",
    "means = pd.DataFrame(columns=['pso', 'aco', 'lawn'])\n",
    "\n",
    "means.pso = pso_step_means\n",
    "means.aco = aco_step_means\n",
    "means.lawn = lawn_step_means\n",
    "means = means.dropna()\n",
    "\n",
    "backup['means'] = means\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate summary plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "m_plot = means.plot(style=['r', 'g', 'b']) \n",
    "m_plot.set_title('Mean Algorithm Performance')\n",
    "m_plot.set_xlabel('Plant Target Number')\n",
    "m_plot.set_ylabel('Time to Target Threshold') \n",
    "m_plot_fig = m_plot.get_figure()\n",
    "m_plot_fig.savefig('thesis/images/means_line_plot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "\n",
    "pso_step_mean_plot = pso_step_means.plot.box()\n",
    "pso_step_mean_plot.set_title('Distribution of PSO Performanc e')\n",
    "pso_step_mean_plot.set_ylabel('Time to Target Threshold')\n",
    "pso_step_mean_fig = pso_step_mean_plot.get_figure()\n",
    "pso_step_mean_fig.savefig('thesis/images/pso_mean_box_plot.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "aco_step_mean_plot = aco_step_means.plot.box()\n",
    "aco_step_mean_plot.set_title('Distribution of ACO Performance')\n",
    "aco_step_mean_plot.set_ylabel('Time to Target Threshold')\n",
    "aco_step_mean_fig = aco_step_mean_plot.get_figure()\n",
    "aco_step_mean_fig.savefig('thesis/images/aco_mean_box_plot.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "lawn_step_mean_plot = lawn_step_means.plot.box()\n",
    "lawn_step_mean_plot.set_title('Distribution of Lawn Performance')\n",
    "lawn_step_mean_plot.set_ylabel('Time to Target Threshold')\n",
    "lawn_step_mean_fig = lawn_step_mean_plot.get_figure()\n",
    "lawn_step_mean_fig.savefig('thesis/images/lawn_mean_box_plot.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "mean_plot = means.plot.box()\n",
    "mean_plot.set_title('Performance Distributions')\n",
    "mean_plot.set_ylabel('Time to Target Threshold')\n",
    "mean_fig = mean_plot.get_figure()\n",
    "mean_fig.savefig('thesis/images/all_means_box_plot.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Significance Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the means backup file already exists, we can load that instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    pso           aco          lawn\n",
      "TargetNum                                          \n",
      "2            407.750000    407.250000   1568.000000\n",
      "3            741.333333    749.250000   7124.500000\n",
      "4            723.500000    748.250000   4703.500000\n",
      "5            774.000000    774.000000   4392.666667\n",
      "12          4277.500000   4607.250000  59524.000000\n",
      "13          4567.500000   4903.000000  55488.666667\n",
      "14          4929.500000   4917.000000  62760.666667\n",
      "15          4898.666667   4887.666667  55574.000000\n",
      "16          6384.000000   6388.000000  62564.666667\n",
      "17          6490.666667   7362.500000  67697.666667\n",
      "18          4734.000000   4784.000000  60794.500000\n",
      "19          6814.250000   5789.666667  61050.333333\n",
      "20          5080.000000   5653.500000  60168.000000\n",
      "21          5693.000000   5460.500000  57930.000000\n",
      "22          5367.333333   5236.500000  64139.333333\n",
      "23          5520.000000   5619.000000  65296.000000\n",
      "24          5912.333333   5374.500000  62720.500000\n",
      "25          5872.000000   5592.666667  64694.000000\n",
      "26          7719.000000   6404.000000  64817.000000\n",
      "27          6422.000000   6690.250000  68636.000000\n",
      "28          8114.333333   7583.500000  68121.000000\n",
      "29          7109.000000   6306.000000  68660.000000\n",
      "30          6790.666667   6839.000000  69506.000000\n",
      "31          6456.000000   6392.000000  66764.000000\n",
      "32          6609.500000   6890.250000  63040.666667\n",
      "33          6516.000000   6494.000000  66437.500000\n",
      "34          6522.000000   6710.500000  68573.000000\n",
      "35          6663.500000   7047.000000  63840.666667\n",
      "36          6994.000000   6990.000000  64729.666667\n",
      "37          7179.500000   7148.500000  66329.000000\n",
      "41         18057.000000  16641.333333  65415.500000\n",
      "42         19607.500000  19125.500000  68494.000000\n",
      "43          8332.000000   8384.000000  64944.666667\n",
      "45         12921.750000  18103.000000  68592.750000\n",
      "46         16939.000000  16866.000000  71788.000000\n",
      "47         12512.000000  17920.000000  68698.666667\n",
      "50         17104.000000  14833.666667  70162.000000\n"
     ]
    }
   ],
   "source": [
    "# Load pre-processed means from HDF5 file\n",
    "\n",
    "means = pd.read_hdf('sample/preprocessed/backup.h5')\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a t-test on the generated means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run independent t-test\n",
    "ind_t_test_PA = ttest_ind(means.pso,means.aco)\n",
    "ind_t_test_PL = ttest_ind(means.pso,means.lawn)\n",
    "ind_t_test_AL = ttest_ind(means.aco,means.lawn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a p-value of ~0.9 between aco and pso, indicating that there is no statistical significance between the two means. More interestingly though, we have p-values of < 0.05 when performed against pso/aco and the lawn means, this is an indication of statistical significance, telling us that our null-hypothesis is provably false!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean difference between the distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pso = means.pso.mean()\n",
    "mean_aco = means.aco.mean()\n",
    "mean_lawn = means.lawn.mean()\n",
    "\n",
    "diff_mean_PA = mean_pso - mean_aco\n",
    "diff_mean_PL = mean_pso - mean_lawn\n",
    "diff_mean_AL = mean_aco - mean_lawn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the 95% confidence interval of the mean sets using the Margin of Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sample sizes\n",
    "NP = means.pso.size\n",
    "NA = means.aco.size\n",
    "NL = means.lawn.size\n",
    "\n",
    "# Compute the degrees of freedom\n",
    "DF_PA = means.pso.size + means.aco.size - 2\n",
    "DF_PL = means.pso.size + means.lawn.size - 2\n",
    "DF_AL = means.aco.size + means.lawn.size - 2\n",
    "\n",
    "# Compute our t-values\n",
    "t_PA = t.ppf([0.975], DF_PA)\n",
    "t_PL = t.ppf([0.975], DF_PL)\n",
    "t_AL = t.ppf([0.975], DF_AL)\n",
    "\n",
    "# Compute the standard deviations of the samples\n",
    "std_pso = means.pso.std()\n",
    "std_aco = means.aco.std()\n",
    "std_lawn = means.lawn.std()\n",
    "\n",
    "# Compute the average standard deviations between the samples\n",
    "std_PA = sqrt(((NP - 1)*(std_pso)**2 + (NA - 1)*(std_aco)**2) / DF_PA)\n",
    "std_PL = sqrt(((NP - 1)*(std_pso)**2 + (NL - 1)*(std_lawn)**2) / DF_PL)\n",
    "std_AL = sqrt(((NA - 1)*(std_aco)**2 + (NA - 1)*(std_lawn)**2) / DF_AL)\n",
    "\n",
    "# Compute our Margin of Errors\n",
    "MoE_PA = t_PA * std_PA * sqrt(1/NP + 1/NA)\n",
    "MoE_PL = t_PL * std_PL * sqrt(1/NP + 1/NL)\n",
    "MoE_AL = t_AL * std_AL * sqrt(1/NA + 1/NL)\n",
    "\n",
    "print('The results of the independent t-tests are: \\nPSO:ACO -> tt-value = {:4.3f} tp-value = {:4.3f} \\nPSO:LAWN -> tt-value = {:4.3f} tp-value = {:4.3f} \\nACO:LAWN -> tt-value = {:4.3f} tp-value = {:4.3f}'.format(ind_t_test_PA[0],ind_t_test_PA[1],ind_t_test_PL[0],ind_t_test_PL[1],ind_t_test_AL[0],ind_t_test_AL[1]))\n",
    "print ('\\nThe difference between groups is \\nPSO:ACO {:3.1f} [{} to {}] (mean [95% CI]) \\nPSO:LAWN {:3.1f} [{} to {}] (mean [95% CI]) \\nACO:LAWN {:3.1f} [{} to {}] (mean [95% CI])'.format(diff_mean_PA, diff_mean_PA - MoE_PA, diff_mean_PA + MoE_PA, diff_mean_PL, diff_mean_PL - MoE_PL, diff_mean_PL + MoE_PL, diff_mean_AL, diff_mean_AL - MoE_AL, diff_mean_AL + MoE_AL))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
